{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Dvc Task API Reference","title":"Welcome to Dvc Task"},{"location":"#welcome-to-dvc-task","text":"API Reference","title":"Welcome to Dvc Task"},{"location":"reference/dvc_task/","text":"DVC Task.","title":"Dvc task"},{"location":"reference/dvc_task/exceptions/","text":"Exception classes. DvcTaskError Bases: Exception Base DVC Task exception. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/exceptions.py 4 5 class DvcTaskError ( Exception ): \"\"\"Base DVC Task exception.\"\"\"","title":"Exceptions"},{"location":"reference/dvc_task/exceptions/#dvc_task.exceptions.DvcTaskError","text":"Bases: Exception Base DVC Task exception. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/exceptions.py 4 5 class DvcTaskError ( Exception ): \"\"\"Base DVC Task exception.\"\"\"","title":"DvcTaskError"},{"location":"reference/dvc_task/utils/","text":"General utilities. makedirs ( path , exist_ok = False , mode = None ) Make the specified directory and any parent directories. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/utils.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def makedirs ( path : str , exist_ok : bool = False , mode : Optional [ int ] = None ): \"\"\"Make the specified directory and any parent directories.\"\"\" if mode is None : os . makedirs ( path , exist_ok = exist_ok ) return # Modified version of os.makedirs() with support for extended mode # (e.g. S_ISGID) head , tail = os . path . split ( path ) if not tail : head , tail = os . path . split ( head ) if head and tail and not os . path . exists ( head ): try : makedirs ( head , exist_ok = exist_ok , mode = mode ) except FileExistsError : # Defeats race condition when another thread created the path pass cdir = os . curdir if tail == cdir : # foo/newdir/. exists if foo/newdir exists return try : os . mkdir ( path , mode ) except OSError : # Cannot rely on checking for EEXIST, since the operating system # could give priority to other errors like EACCES or EROFS if not exist_ok or not os . path . isdir ( path ): raise try : os . chmod ( path , mode ) except OSError : logger . debug ( \"failed to chmod ' %o ' ' %s '\" , mode , path , exc_info = True ) remove ( path ) Remove the specified path. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/utils.py 35 36 37 38 39 40 41 42 43 44 45 def remove ( path : str ): \"\"\"Remove the specified path.\"\"\" logger . debug ( \"Removing ' %s '\" , path ) try : if os . path . isdir ( path ): shutil . rmtree ( path , onerror = _chmod ) else : _unlink ( path , _chmod ) except OSError as exc : if exc . errno != errno . ENOENT : raise unc_path ( path ) Return UNC formatted path. Returns the unmodified path on posix platforms. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/utils.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def unc_path ( path : str ) -> str : \"\"\"Return UNC formatted path. Returns the unmodified path on posix platforms. \"\"\" # Celery/Kombu URLs only take absolute filesystem paths # (UNC paths on windows) path = os . path . abspath ( path ) if os . name != \"nt\" : return path drive , tail = os . path . splitdrive ( path ) if drive . endswith ( \":\" ): return f \" \\\\\\\\ ? \\\\ { drive }{ tail } \" return f \" { drive }{ tail } \"","title":"Utils"},{"location":"reference/dvc_task/utils/#dvc_task.utils.makedirs","text":"Make the specified directory and any parent directories. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/utils.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def makedirs ( path : str , exist_ok : bool = False , mode : Optional [ int ] = None ): \"\"\"Make the specified directory and any parent directories.\"\"\" if mode is None : os . makedirs ( path , exist_ok = exist_ok ) return # Modified version of os.makedirs() with support for extended mode # (e.g. S_ISGID) head , tail = os . path . split ( path ) if not tail : head , tail = os . path . split ( head ) if head and tail and not os . path . exists ( head ): try : makedirs ( head , exist_ok = exist_ok , mode = mode ) except FileExistsError : # Defeats race condition when another thread created the path pass cdir = os . curdir if tail == cdir : # foo/newdir/. exists if foo/newdir exists return try : os . mkdir ( path , mode ) except OSError : # Cannot rely on checking for EEXIST, since the operating system # could give priority to other errors like EACCES or EROFS if not exist_ok or not os . path . isdir ( path ): raise try : os . chmod ( path , mode ) except OSError : logger . debug ( \"failed to chmod ' %o ' ' %s '\" , mode , path , exc_info = True )","title":"makedirs()"},{"location":"reference/dvc_task/utils/#dvc_task.utils.remove","text":"Remove the specified path. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/utils.py 35 36 37 38 39 40 41 42 43 44 45 def remove ( path : str ): \"\"\"Remove the specified path.\"\"\" logger . debug ( \"Removing ' %s '\" , path ) try : if os . path . isdir ( path ): shutil . rmtree ( path , onerror = _chmod ) else : _unlink ( path , _chmod ) except OSError as exc : if exc . errno != errno . ENOENT : raise","title":"remove()"},{"location":"reference/dvc_task/utils/#dvc_task.utils.unc_path","text":"Return UNC formatted path. Returns the unmodified path on posix platforms. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/utils.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def unc_path ( path : str ) -> str : \"\"\"Return UNC formatted path. Returns the unmodified path on posix platforms. \"\"\" # Celery/Kombu URLs only take absolute filesystem paths # (UNC paths on windows) path = os . path . abspath ( path ) if os . name != \"nt\" : return path drive , tail = os . path . splitdrive ( path ) if drive . endswith ( \":\" ): return f \" \\\\\\\\ ? \\\\ { drive }{ tail } \" return f \" { drive }{ tail } \"","title":"unc_path()"},{"location":"reference/dvc_task/app/","text":"DVC Task app factories. FSApp Bases: Celery Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 class FSApp ( Celery ): \"\"\"Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend \"\"\" def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _processed_msg_path_cache : Dict [ str , str ] = {} self . _queued_msg_path_cache : Dict [ str , str ] = {} def __reduce_keys__ ( self ) -> Dict [ str , Any ]: keys = super () . __reduce_keys__ () # type: ignore[misc] keys . update ({ \"wdir\" : self . wdir }) return keys def _iter_folder ( self , folder_name : str , path_cache : Dict [ str , str ], queue : Optional [ str ] = None , ) -> Iterator [ Message ]: \"\"\"Iterate over queued tasks inside a folder Arguments: folder_name: the folder to iterate path_cache: cache of message path. queue: Optional name of queue. \"\"\" with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : # type: ignore[attr-defined] folder = getattr ( channel , folder_name ) for filename in sorted ( os . listdir ( folder )): path = os . path . join ( folder , filename ) try : with open ( path , \"rb\" ) as fobj : lock ( fobj , LOCK_SH ) try : payload = fobj . read () finally : unlock ( fobj ) except FileNotFoundError : # Messages returned by `listdir` call may have been # acknowledged and moved to `processed_folder` by the # time we try to read them here continue if not payload : continue msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) path_cache [ msg . delivery_tag ] = path if queue is None : yield msg else : delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg def _iter_data_folder ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: yield from self . _iter_folder ( \"data_folder_in\" , self . _queued_msg_path_cache , queue = queue ) def _iter_processed_folder ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: yield from self . _iter_folder ( \"processed_folder\" , self . _processed_msg_path_cache , queue = queue ) def iter_queued ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue yield from self . _iter_data_folder ( queue = queue ) def iter_processed ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue yield from self . _iter_processed_folder ( queue = queue ) @staticmethod def _delete_msg ( delivery_tag : str , msg_collection : Iterable [ Message ], path_cache : Dict [ str , str ], ): \"\"\"delete the specified message. Arguments: delivery_tag: delivery tag of the message to be deleted. msg_collection: where to found this message. path_cache: cache of message path. Raises: ValueError: Invalid delivery_tag \"\"\" path = path_cache . get ( delivery_tag ) if path and os . path . exists ( path ): remove ( path ) del path_cache [ delivery_tag ] return for msg in msg_collection : if msg . delivery_tag == delivery_tag : remove ( path_cache [ delivery_tag ]) del path_cache [ delivery_tag ] return raise ValueError ( f \"Message ' { delivery_tag } ' not found\" ) def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_queued (), self . _queued_msg_path_cache ) def purge ( self , delivery_tag : str ): \"\"\"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_processed (), self . _processed_msg_path_cache ) def _gc ( self , exclude : Optional [ List [ str ]] = None ): \"\"\"Garbage collect expired FS broker messages. Arguments: exclude: Exclude (do not garbage collect) messages from the specified queues. \"\"\" def _delete_expired ( msg : Message , queues : Set [ str ], now : float , cache : Dict [ str , str ], include_tickets : bool = False , ): assert isinstance ( msg . properties , dict ) properties = cast ( Dict [ str , Any ], msg . properties ) delivery_info : Dict [ str , str ] = properties . get ( \"delivery_info\" , {}) if queues : routing_key = delivery_info . get ( \"routing_key\" ) if routing_key and routing_key in queues : return headers = cast ( Dict [ str , Any ], msg . headers ) expires : Optional [ float ] = headers . get ( \"expires\" ) ticket = msg . headers . get ( \"ticket\" ) if include_tickets and ticket or ( expires is not None and expires <= now ): assert msg . delivery_tag try : self . _delete_msg ( msg . delivery_tag , [], cache ) except ValueError : pass queues = set ( exclude ) if exclude else set () now = datetime . now () . timestamp () for msg in self . _iter_data_folder (): _delete_expired ( msg , queues , now , self . _queued_msg_path_cache ) for msg in self . _iter_processed_folder (): _delete_expired ( msg , queues , now , self . _processed_msg_path_cache , include_tickets = True ) def clean ( self ): \"\"\"Clean extraneous celery messages from this FSApp.\"\"\" self . _gc ( exclude = [ self . conf . task_default_queue ]) self . _clean_pidbox ( f \"reply. { self . conf . task_default_queue } .pidbox\" ) def _clean_pidbox ( self , exchange : str ): \"\"\"Clean pidbox replies for the specified exchange.\"\"\" def _delete_replies ( msg : Message , exchange : str , cache : Dict [ str , str ]): assert isinstance ( msg . properties , dict ) properties = cast ( Dict [ str , Any ], msg . properties ) delivery_info : Dict [ str , str ] = properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"exchange\" , \"\" ) == exchange : assert msg . delivery_tag try : self . _delete_msg ( msg . delivery_tag , [], cache ) except ValueError : pass for msg in self . _iter_data_folder (): _delete_replies ( msg , exchange , self . _queued_msg_path_cache ) __init__ ( args , wdir = None , mkdir = False , task_serializer = 'json' , result_serializer = 'json' , kwargs ) Construct an FSApp. Parameters: Name Type Description Default wdir Optional [ str ] App broker/results directory. Defaults to current working directory. None mkdir bool Create broker/results subdirectories if they do not already exist. False task_serializer str Default task serializer. 'json' result_serializer str Default result serializer. 'json' Additional arguments will be passed into the Celery constructor. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _processed_msg_path_cache : Dict [ str , str ] = {} self . _queued_msg_path_cache : Dict [ str , str ] = {} clean () Clean extraneous celery messages from this FSApp. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 265 266 267 268 def clean ( self ): \"\"\"Clean extraneous celery messages from this FSApp.\"\"\" self . _gc ( exclude = [ self . conf . task_default_queue ]) self . _clean_pidbox ( f \"reply. { self . conf . task_default_queue } .pidbox\" ) iter_processed ( queue = None ) Iterate over tasks which have been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 162 163 164 165 166 167 168 169 def iter_processed ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue yield from self . _iter_processed_folder ( queue = queue ) iter_queued ( queue = None ) Iterate over queued tasks which have not been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 153 154 155 156 157 158 159 160 def iter_queued ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue yield from self . _iter_data_folder ( queue = queue ) purge ( delivery_tag ) Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 211 212 213 214 215 216 217 218 219 220 221 222 def purge ( self , delivery_tag : str ): \"\"\"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_processed (), self . _processed_msg_path_cache ) reject ( delivery_tag ) Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 200 201 202 203 204 205 206 207 208 209 def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_queued (), self . _queued_msg_path_cache )","title":"App"},{"location":"reference/dvc_task/app/#dvc_task.app.FSApp","text":"Bases: Celery Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 class FSApp ( Celery ): \"\"\"Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend \"\"\" def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _processed_msg_path_cache : Dict [ str , str ] = {} self . _queued_msg_path_cache : Dict [ str , str ] = {} def __reduce_keys__ ( self ) -> Dict [ str , Any ]: keys = super () . __reduce_keys__ () # type: ignore[misc] keys . update ({ \"wdir\" : self . wdir }) return keys def _iter_folder ( self , folder_name : str , path_cache : Dict [ str , str ], queue : Optional [ str ] = None , ) -> Iterator [ Message ]: \"\"\"Iterate over queued tasks inside a folder Arguments: folder_name: the folder to iterate path_cache: cache of message path. queue: Optional name of queue. \"\"\" with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : # type: ignore[attr-defined] folder = getattr ( channel , folder_name ) for filename in sorted ( os . listdir ( folder )): path = os . path . join ( folder , filename ) try : with open ( path , \"rb\" ) as fobj : lock ( fobj , LOCK_SH ) try : payload = fobj . read () finally : unlock ( fobj ) except FileNotFoundError : # Messages returned by `listdir` call may have been # acknowledged and moved to `processed_folder` by the # time we try to read them here continue if not payload : continue msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) path_cache [ msg . delivery_tag ] = path if queue is None : yield msg else : delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg def _iter_data_folder ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: yield from self . _iter_folder ( \"data_folder_in\" , self . _queued_msg_path_cache , queue = queue ) def _iter_processed_folder ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: yield from self . _iter_folder ( \"processed_folder\" , self . _processed_msg_path_cache , queue = queue ) def iter_queued ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue yield from self . _iter_data_folder ( queue = queue ) def iter_processed ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue yield from self . _iter_processed_folder ( queue = queue ) @staticmethod def _delete_msg ( delivery_tag : str , msg_collection : Iterable [ Message ], path_cache : Dict [ str , str ], ): \"\"\"delete the specified message. Arguments: delivery_tag: delivery tag of the message to be deleted. msg_collection: where to found this message. path_cache: cache of message path. Raises: ValueError: Invalid delivery_tag \"\"\" path = path_cache . get ( delivery_tag ) if path and os . path . exists ( path ): remove ( path ) del path_cache [ delivery_tag ] return for msg in msg_collection : if msg . delivery_tag == delivery_tag : remove ( path_cache [ delivery_tag ]) del path_cache [ delivery_tag ] return raise ValueError ( f \"Message ' { delivery_tag } ' not found\" ) def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_queued (), self . _queued_msg_path_cache ) def purge ( self , delivery_tag : str ): \"\"\"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_processed (), self . _processed_msg_path_cache ) def _gc ( self , exclude : Optional [ List [ str ]] = None ): \"\"\"Garbage collect expired FS broker messages. Arguments: exclude: Exclude (do not garbage collect) messages from the specified queues. \"\"\" def _delete_expired ( msg : Message , queues : Set [ str ], now : float , cache : Dict [ str , str ], include_tickets : bool = False , ): assert isinstance ( msg . properties , dict ) properties = cast ( Dict [ str , Any ], msg . properties ) delivery_info : Dict [ str , str ] = properties . get ( \"delivery_info\" , {}) if queues : routing_key = delivery_info . get ( \"routing_key\" ) if routing_key and routing_key in queues : return headers = cast ( Dict [ str , Any ], msg . headers ) expires : Optional [ float ] = headers . get ( \"expires\" ) ticket = msg . headers . get ( \"ticket\" ) if include_tickets and ticket or ( expires is not None and expires <= now ): assert msg . delivery_tag try : self . _delete_msg ( msg . delivery_tag , [], cache ) except ValueError : pass queues = set ( exclude ) if exclude else set () now = datetime . now () . timestamp () for msg in self . _iter_data_folder (): _delete_expired ( msg , queues , now , self . _queued_msg_path_cache ) for msg in self . _iter_processed_folder (): _delete_expired ( msg , queues , now , self . _processed_msg_path_cache , include_tickets = True ) def clean ( self ): \"\"\"Clean extraneous celery messages from this FSApp.\"\"\" self . _gc ( exclude = [ self . conf . task_default_queue ]) self . _clean_pidbox ( f \"reply. { self . conf . task_default_queue } .pidbox\" ) def _clean_pidbox ( self , exchange : str ): \"\"\"Clean pidbox replies for the specified exchange.\"\"\" def _delete_replies ( msg : Message , exchange : str , cache : Dict [ str , str ]): assert isinstance ( msg . properties , dict ) properties = cast ( Dict [ str , Any ], msg . properties ) delivery_info : Dict [ str , str ] = properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"exchange\" , \"\" ) == exchange : assert msg . delivery_tag try : self . _delete_msg ( msg . delivery_tag , [], cache ) except ValueError : pass for msg in self . _iter_data_folder (): _delete_replies ( msg , exchange , self . _queued_msg_path_cache )","title":"FSApp"},{"location":"reference/dvc_task/app/#dvc_task.app.filesystem.FSApp.__init__","text":"Construct an FSApp. Parameters: Name Type Description Default wdir Optional [ str ] App broker/results directory. Defaults to current working directory. None mkdir bool Create broker/results subdirectories if they do not already exist. False task_serializer str Default task serializer. 'json' result_serializer str Default result serializer. 'json' Additional arguments will be passed into the Celery constructor. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _processed_msg_path_cache : Dict [ str , str ] = {} self . _queued_msg_path_cache : Dict [ str , str ] = {}","title":"__init__()"},{"location":"reference/dvc_task/app/#dvc_task.app.filesystem.FSApp.clean","text":"Clean extraneous celery messages from this FSApp. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 265 266 267 268 def clean ( self ): \"\"\"Clean extraneous celery messages from this FSApp.\"\"\" self . _gc ( exclude = [ self . conf . task_default_queue ]) self . _clean_pidbox ( f \"reply. { self . conf . task_default_queue } .pidbox\" )","title":"clean()"},{"location":"reference/dvc_task/app/#dvc_task.app.filesystem.FSApp.iter_processed","text":"Iterate over tasks which have been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 162 163 164 165 166 167 168 169 def iter_processed ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue yield from self . _iter_processed_folder ( queue = queue )","title":"iter_processed()"},{"location":"reference/dvc_task/app/#dvc_task.app.filesystem.FSApp.iter_queued","text":"Iterate over queued tasks which have not been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 153 154 155 156 157 158 159 160 def iter_queued ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue yield from self . _iter_data_folder ( queue = queue )","title":"iter_queued()"},{"location":"reference/dvc_task/app/#dvc_task.app.filesystem.FSApp.purge","text":"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 211 212 213 214 215 216 217 218 219 220 221 222 def purge ( self , delivery_tag : str ): \"\"\"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_processed (), self . _processed_msg_path_cache )","title":"purge()"},{"location":"reference/dvc_task/app/#dvc_task.app.filesystem.FSApp.reject","text":"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 200 201 202 203 204 205 206 207 208 209 def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_queued (), self . _queued_msg_path_cache )","title":"reject()"},{"location":"reference/dvc_task/app/filesystem/","text":"(Local) filesystem based Celery application. FSApp Bases: Celery Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 class FSApp ( Celery ): \"\"\"Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend \"\"\" def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _processed_msg_path_cache : Dict [ str , str ] = {} self . _queued_msg_path_cache : Dict [ str , str ] = {} def __reduce_keys__ ( self ) -> Dict [ str , Any ]: keys = super () . __reduce_keys__ () # type: ignore[misc] keys . update ({ \"wdir\" : self . wdir }) return keys def _iter_folder ( self , folder_name : str , path_cache : Dict [ str , str ], queue : Optional [ str ] = None , ) -> Iterator [ Message ]: \"\"\"Iterate over queued tasks inside a folder Arguments: folder_name: the folder to iterate path_cache: cache of message path. queue: Optional name of queue. \"\"\" with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : # type: ignore[attr-defined] folder = getattr ( channel , folder_name ) for filename in sorted ( os . listdir ( folder )): path = os . path . join ( folder , filename ) try : with open ( path , \"rb\" ) as fobj : lock ( fobj , LOCK_SH ) try : payload = fobj . read () finally : unlock ( fobj ) except FileNotFoundError : # Messages returned by `listdir` call may have been # acknowledged and moved to `processed_folder` by the # time we try to read them here continue if not payload : continue msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) path_cache [ msg . delivery_tag ] = path if queue is None : yield msg else : delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg def _iter_data_folder ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: yield from self . _iter_folder ( \"data_folder_in\" , self . _queued_msg_path_cache , queue = queue ) def _iter_processed_folder ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: yield from self . _iter_folder ( \"processed_folder\" , self . _processed_msg_path_cache , queue = queue ) def iter_queued ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue yield from self . _iter_data_folder ( queue = queue ) def iter_processed ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue yield from self . _iter_processed_folder ( queue = queue ) @staticmethod def _delete_msg ( delivery_tag : str , msg_collection : Iterable [ Message ], path_cache : Dict [ str , str ], ): \"\"\"delete the specified message. Arguments: delivery_tag: delivery tag of the message to be deleted. msg_collection: where to found this message. path_cache: cache of message path. Raises: ValueError: Invalid delivery_tag \"\"\" path = path_cache . get ( delivery_tag ) if path and os . path . exists ( path ): remove ( path ) del path_cache [ delivery_tag ] return for msg in msg_collection : if msg . delivery_tag == delivery_tag : remove ( path_cache [ delivery_tag ]) del path_cache [ delivery_tag ] return raise ValueError ( f \"Message ' { delivery_tag } ' not found\" ) def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_queued (), self . _queued_msg_path_cache ) def purge ( self , delivery_tag : str ): \"\"\"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_processed (), self . _processed_msg_path_cache ) def _gc ( self , exclude : Optional [ List [ str ]] = None ): \"\"\"Garbage collect expired FS broker messages. Arguments: exclude: Exclude (do not garbage collect) messages from the specified queues. \"\"\" def _delete_expired ( msg : Message , queues : Set [ str ], now : float , cache : Dict [ str , str ], include_tickets : bool = False , ): assert isinstance ( msg . properties , dict ) properties = cast ( Dict [ str , Any ], msg . properties ) delivery_info : Dict [ str , str ] = properties . get ( \"delivery_info\" , {}) if queues : routing_key = delivery_info . get ( \"routing_key\" ) if routing_key and routing_key in queues : return headers = cast ( Dict [ str , Any ], msg . headers ) expires : Optional [ float ] = headers . get ( \"expires\" ) ticket = msg . headers . get ( \"ticket\" ) if include_tickets and ticket or ( expires is not None and expires <= now ): assert msg . delivery_tag try : self . _delete_msg ( msg . delivery_tag , [], cache ) except ValueError : pass queues = set ( exclude ) if exclude else set () now = datetime . now () . timestamp () for msg in self . _iter_data_folder (): _delete_expired ( msg , queues , now , self . _queued_msg_path_cache ) for msg in self . _iter_processed_folder (): _delete_expired ( msg , queues , now , self . _processed_msg_path_cache , include_tickets = True ) def clean ( self ): \"\"\"Clean extraneous celery messages from this FSApp.\"\"\" self . _gc ( exclude = [ self . conf . task_default_queue ]) self . _clean_pidbox ( f \"reply. { self . conf . task_default_queue } .pidbox\" ) def _clean_pidbox ( self , exchange : str ): \"\"\"Clean pidbox replies for the specified exchange.\"\"\" def _delete_replies ( msg : Message , exchange : str , cache : Dict [ str , str ]): assert isinstance ( msg . properties , dict ) properties = cast ( Dict [ str , Any ], msg . properties ) delivery_info : Dict [ str , str ] = properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"exchange\" , \"\" ) == exchange : assert msg . delivery_tag try : self . _delete_msg ( msg . delivery_tag , [], cache ) except ValueError : pass for msg in self . _iter_data_folder (): _delete_replies ( msg , exchange , self . _queued_msg_path_cache ) __init__ ( args , wdir = None , mkdir = False , task_serializer = 'json' , result_serializer = 'json' , kwargs ) Construct an FSApp. Parameters: Name Type Description Default wdir Optional [ str ] App broker/results directory. Defaults to current working directory. None mkdir bool Create broker/results subdirectories if they do not already exist. False task_serializer str Default task serializer. 'json' result_serializer str Default result serializer. 'json' Additional arguments will be passed into the Celery constructor. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _processed_msg_path_cache : Dict [ str , str ] = {} self . _queued_msg_path_cache : Dict [ str , str ] = {} clean () Clean extraneous celery messages from this FSApp. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 265 266 267 268 def clean ( self ): \"\"\"Clean extraneous celery messages from this FSApp.\"\"\" self . _gc ( exclude = [ self . conf . task_default_queue ]) self . _clean_pidbox ( f \"reply. { self . conf . task_default_queue } .pidbox\" ) iter_processed ( queue = None ) Iterate over tasks which have been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 162 163 164 165 166 167 168 169 def iter_processed ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue yield from self . _iter_processed_folder ( queue = queue ) iter_queued ( queue = None ) Iterate over queued tasks which have not been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 153 154 155 156 157 158 159 160 def iter_queued ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue yield from self . _iter_data_folder ( queue = queue ) purge ( delivery_tag ) Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 211 212 213 214 215 216 217 218 219 220 221 222 def purge ( self , delivery_tag : str ): \"\"\"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_processed (), self . _processed_msg_path_cache ) reject ( delivery_tag ) Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 200 201 202 203 204 205 206 207 208 209 def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_queued (), self . _queued_msg_path_cache )","title":"Filesystem"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp","text":"Bases: Celery Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 class FSApp ( Celery ): \"\"\"Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend \"\"\" def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _processed_msg_path_cache : Dict [ str , str ] = {} self . _queued_msg_path_cache : Dict [ str , str ] = {} def __reduce_keys__ ( self ) -> Dict [ str , Any ]: keys = super () . __reduce_keys__ () # type: ignore[misc] keys . update ({ \"wdir\" : self . wdir }) return keys def _iter_folder ( self , folder_name : str , path_cache : Dict [ str , str ], queue : Optional [ str ] = None , ) -> Iterator [ Message ]: \"\"\"Iterate over queued tasks inside a folder Arguments: folder_name: the folder to iterate path_cache: cache of message path. queue: Optional name of queue. \"\"\" with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : # type: ignore[attr-defined] folder = getattr ( channel , folder_name ) for filename in sorted ( os . listdir ( folder )): path = os . path . join ( folder , filename ) try : with open ( path , \"rb\" ) as fobj : lock ( fobj , LOCK_SH ) try : payload = fobj . read () finally : unlock ( fobj ) except FileNotFoundError : # Messages returned by `listdir` call may have been # acknowledged and moved to `processed_folder` by the # time we try to read them here continue if not payload : continue msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) path_cache [ msg . delivery_tag ] = path if queue is None : yield msg else : delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg def _iter_data_folder ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: yield from self . _iter_folder ( \"data_folder_in\" , self . _queued_msg_path_cache , queue = queue ) def _iter_processed_folder ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: yield from self . _iter_folder ( \"processed_folder\" , self . _processed_msg_path_cache , queue = queue ) def iter_queued ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue yield from self . _iter_data_folder ( queue = queue ) def iter_processed ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue yield from self . _iter_processed_folder ( queue = queue ) @staticmethod def _delete_msg ( delivery_tag : str , msg_collection : Iterable [ Message ], path_cache : Dict [ str , str ], ): \"\"\"delete the specified message. Arguments: delivery_tag: delivery tag of the message to be deleted. msg_collection: where to found this message. path_cache: cache of message path. Raises: ValueError: Invalid delivery_tag \"\"\" path = path_cache . get ( delivery_tag ) if path and os . path . exists ( path ): remove ( path ) del path_cache [ delivery_tag ] return for msg in msg_collection : if msg . delivery_tag == delivery_tag : remove ( path_cache [ delivery_tag ]) del path_cache [ delivery_tag ] return raise ValueError ( f \"Message ' { delivery_tag } ' not found\" ) def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_queued (), self . _queued_msg_path_cache ) def purge ( self , delivery_tag : str ): \"\"\"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_processed (), self . _processed_msg_path_cache ) def _gc ( self , exclude : Optional [ List [ str ]] = None ): \"\"\"Garbage collect expired FS broker messages. Arguments: exclude: Exclude (do not garbage collect) messages from the specified queues. \"\"\" def _delete_expired ( msg : Message , queues : Set [ str ], now : float , cache : Dict [ str , str ], include_tickets : bool = False , ): assert isinstance ( msg . properties , dict ) properties = cast ( Dict [ str , Any ], msg . properties ) delivery_info : Dict [ str , str ] = properties . get ( \"delivery_info\" , {}) if queues : routing_key = delivery_info . get ( \"routing_key\" ) if routing_key and routing_key in queues : return headers = cast ( Dict [ str , Any ], msg . headers ) expires : Optional [ float ] = headers . get ( \"expires\" ) ticket = msg . headers . get ( \"ticket\" ) if include_tickets and ticket or ( expires is not None and expires <= now ): assert msg . delivery_tag try : self . _delete_msg ( msg . delivery_tag , [], cache ) except ValueError : pass queues = set ( exclude ) if exclude else set () now = datetime . now () . timestamp () for msg in self . _iter_data_folder (): _delete_expired ( msg , queues , now , self . _queued_msg_path_cache ) for msg in self . _iter_processed_folder (): _delete_expired ( msg , queues , now , self . _processed_msg_path_cache , include_tickets = True ) def clean ( self ): \"\"\"Clean extraneous celery messages from this FSApp.\"\"\" self . _gc ( exclude = [ self . conf . task_default_queue ]) self . _clean_pidbox ( f \"reply. { self . conf . task_default_queue } .pidbox\" ) def _clean_pidbox ( self , exchange : str ): \"\"\"Clean pidbox replies for the specified exchange.\"\"\" def _delete_replies ( msg : Message , exchange : str , cache : Dict [ str , str ]): assert isinstance ( msg . properties , dict ) properties = cast ( Dict [ str , Any ], msg . properties ) delivery_info : Dict [ str , str ] = properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"exchange\" , \"\" ) == exchange : assert msg . delivery_tag try : self . _delete_msg ( msg . delivery_tag , [], cache ) except ValueError : pass for msg in self . _iter_data_folder (): _delete_replies ( msg , exchange , self . _queued_msg_path_cache )","title":"FSApp"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp.__init__","text":"Construct an FSApp. Parameters: Name Type Description Default wdir Optional [ str ] App broker/results directory. Defaults to current working directory. None mkdir bool Create broker/results subdirectories if they do not already exist. False task_serializer str Default task serializer. 'json' result_serializer str Default result serializer. 'json' Additional arguments will be passed into the Celery constructor. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _processed_msg_path_cache : Dict [ str , str ] = {} self . _queued_msg_path_cache : Dict [ str , str ] = {}","title":"__init__()"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp.clean","text":"Clean extraneous celery messages from this FSApp. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 265 266 267 268 def clean ( self ): \"\"\"Clean extraneous celery messages from this FSApp.\"\"\" self . _gc ( exclude = [ self . conf . task_default_queue ]) self . _clean_pidbox ( f \"reply. { self . conf . task_default_queue } .pidbox\" )","title":"clean()"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp.iter_processed","text":"Iterate over tasks which have been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 162 163 164 165 166 167 168 169 def iter_processed ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue yield from self . _iter_processed_folder ( queue = queue )","title":"iter_processed()"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp.iter_queued","text":"Iterate over queued tasks which have not been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 153 154 155 156 157 158 159 160 def iter_queued ( self , queue : Optional [ str ] = None ) -> Iterator [ Message ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue yield from self . _iter_data_folder ( queue = queue )","title":"iter_queued()"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp.purge","text":"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 211 212 213 214 215 216 217 218 219 220 221 222 def purge ( self , delivery_tag : str ): \"\"\"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_processed (), self . _processed_msg_path_cache )","title":"purge()"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp.reject","text":"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/app/filesystem.py 200 201 202 203 204 205 206 207 208 209 def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_queued (), self . _queued_msg_path_cache )","title":"reject()"},{"location":"reference/dvc_task/proc/","text":"Process management module. ManagedProcess Bases: AbstractContextManager Class to manage the specified process with redirected output. stdout and stderr will both be redirected to .out. Interactive processes (requiring stdin input) are currently unsupported. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 class ManagedProcess ( AbstractContextManager ): \"\"\"Class to manage the specified process with redirected output. stdout and stderr will both be redirected to <name>.out. Interactive processes (requiring stdin input) are currently unsupported. \"\"\" def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None def __enter__ ( self ): if self . _proc is None : self . run () return self def __exit__ ( self , * args , ** kwargs ): self . wait () def _close_fds ( self ): with self . _fd_stack : pass def _make_path ( self , path : str ) -> str : return os . path . join ( self . wdir , path ) if self . wdir else path @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) @property def info ( self ) -> \"ProcessInfo\" : \"\"\"Return process information.\"\"\" return ProcessInfo ( pid = self . pid , stdin = None , stdout = self . stdout_path , stderr = None , returncode = self . returncode , ) @property def pid ( self ) -> int : \"\"\"Return process PID. Raises: ValueError: Process is not running. \"\"\" if self . _proc is None : raise ValueError return self . _proc . pid def _make_wdir ( self ): if self . wdir : makedirs ( self . wdir , exist_ok = True ) def _dump ( self ): self . _make_wdir () self . info . dump ( self . info_path ) with open ( self . pidfile_path , \"w\" , encoding = \"utf-8\" ) as fobj : fobj . write ( str ( self . pid )) def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( # nosec B603 self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc except KeyboardInterrupt : pass self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid @classmethod def _spawn ( cls , * args , ** kwargs ): with cls ( * args , ** kwargs ): pass info : ProcessInfo property Return process information. pid : int property Return process PID. Raises: Type Description ValueError Process is not running. __init__ ( args , env = None , wdir = None , name = None ) Construct a MangedProcess. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to be run. required env Optional [ Dict [ str , str ]] Optional environment variables. None wdir Optional [ str ] If specified, redirected output files will be placed in wdir . Defaults to current working directory. None name Optional [ str ] Name to use for this process, if not specified a UUID will be generated instead. None Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None info_path () Return process information file path. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 118 119 120 121 @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) pidfile_path () Return process pidfile path. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 123 124 125 126 @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) run () Run this process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( # nosec B603 self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise spawn ( args , kwargs ) classmethod Spawn a ManagedProcess command in the background. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid stdout_path () Return redirected stdout path. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 113 114 115 116 @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) wait ( timeout = None ) Block until a process started with run has completed. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc except KeyboardInterrupt : pass self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode ProcessInfo dataclass Process information. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 @dataclass class ProcessInfo : \"\"\"Process information.\"\"\" pid : int stdin : Optional [ str ] stdout : Optional [ str ] stderr : Optional [ str ] returncode : Optional [ int ] @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj )) def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" directory , file = os . path . split ( filename ) with tempfile . NamedTemporaryFile ( mode = \"w\" , encoding = \"utf-8\" , dir = directory , prefix = f \" { file } .\" , suffix = \".tmp\" , delete = False , ) as tmp : json . dump ( self . asdict (), tmp ) os . replace ( tmp . name , filename ) asdict () Return this info as a dictionary. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 43 44 45 def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) dump ( filename ) Dump the process information into a file. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 47 48 49 50 51 52 53 54 55 56 57 58 59 def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" directory , file = os . path . split ( filename ) with tempfile . NamedTemporaryFile ( mode = \"w\" , encoding = \"utf-8\" , dir = directory , prefix = f \" { file } .\" , suffix = \".tmp\" , delete = False , ) as tmp : json . dump ( self . asdict (), tmp ) os . replace ( tmp . name , filename ) from_dict ( data ) classmethod Construct ProcessInfo from the specified dictionary. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 32 33 34 35 @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) load ( filename ) classmethod Construct the process information from a file. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 37 38 39 40 41 @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj )) ProcessManager Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 class ProcessManager : \"\"\"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. \"\"\" def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir def __iter__ ( self ) -> Generator [ str , None , None ]: if not os . path . exists ( self . wdir ): return yield from os . listdir ( self . wdir ) @reraise ( FileNotFoundError , KeyError ) def __getitem__ ( self , key : str ) -> \"ProcessInfo\" : info_path = self . _get_info_path ( key ) return ProcessInfo . load ( info_path ) @reraise ( FileNotFoundError , KeyError ) def __setitem__ ( self , key : str , value : \"ProcessInfo\" ): info_path = self . _get_info_path ( key ) value . dump ( info_path ) def __delitem__ ( self , key : str ) -> None : path = os . path . join ( self . wdir , key ) if os . path . exists ( path ): remove ( path ) def _get_info_path ( self , key : str ) -> str : return os . path . join ( self . wdir , key , f \" { key } .json\" ) def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) def send_signal ( self , name : str , sig : int , group : bool = False ): \"\"\"Send `signal` to the specified named process.\"\"\" try : process_info = self [ name ] except KeyError as exc : raise ProcessLookupError from exc if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : if sys . platform != \"win32\" and group : pgid = os . getpgid ( process_info . pid ) # pylint: disable=no-member os . killpg ( pgid , sig ) # pylint: disable=no-member else : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise else : raise ProcessLookupError def interrupt ( self , name : str , group : bool = True ): \"\"\"Send interrupt signal to specified named process\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . CTRL_C_EVENT , group # pylint: disable=no-member ) else : self . send_signal ( name , signal . SIGINT , group ) def terminate ( self , name : str , group : bool = False ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM , group ) def kill ( self , name : str , group : bool = False ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM , group ) else : self . send_signal ( name , signal . SIGKILL , group ) # pylint: disable=no-member def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset ) __init__ ( wdir = None ) Construct a ProcessManager Parameters: Name Type Description Default wdir Optional [ str ] Directory used for storing process information. Defaults to the current working directory. None Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir cleanup ( force = False ) Remove stale (terminated) processes from this manager. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 194 195 196 197 198 199 200 def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue follow ( name , encoding = None , sleep_interval = 1 ) Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Parameters: Name Type Description Default name str Process name. required encoding Optional [ str ] Text encoding for redirected output. Defaults to locale.getpreferredencoding() . None sleep_interval int Sleep interval for follow iterations (when waiting for output). 1 Note Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset ) get ( key , default = None ) Return the specified process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 65 66 67 68 69 70 def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default interrupt ( name , group = True ) Send interrupt signal to specified named process Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 152 153 154 155 156 157 158 159 def interrupt ( self , name : str , group : bool = True ): \"\"\"Send interrupt signal to specified named process\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . CTRL_C_EVENT , group # pylint: disable=no-member ) else : self . send_signal ( name , signal . SIGINT , group ) kill ( name , group = False ) Kill the specified named process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 165 166 167 168 169 170 def kill ( self , name : str , group : bool = False ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM , group ) else : self . send_signal ( name , signal . SIGKILL , group ) # pylint: disable=no-member processes () Iterate over managed processes. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 72 73 74 75 76 77 78 def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue remove ( name , force = False ) Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if force is True`, otherwise an exception will be raised. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] run_signature ( args , name = None , task = None , env = None , immutable = False ) Return signature for a task which runs a command in the background. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to run. required name Optional [ str ] Optional name to use for the spawned process. None task Optional [ str ] Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. None env Optional [ Dict [ str , str ]] Optional environment to be passed into the process. None immutable bool True if the returned Signature should be immutable. False Returns: Type Description Signature Celery signature for the run task. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) send_signal ( name , sig , group = False ) Send signal to the specified named process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def send_signal ( self , name : str , sig : int , group : bool = False ): \"\"\"Send `signal` to the specified named process.\"\"\" try : process_info = self [ name ] except KeyError as exc : raise ProcessLookupError from exc if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : if sys . platform != \"win32\" and group : pgid = os . getpgid ( process_info . pid ) # pylint: disable=no-member os . killpg ( pgid , sig ) # pylint: disable=no-member else : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise else : raise ProcessLookupError terminate ( name , group = False ) Terminate the specified named process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 161 162 163 def terminate ( self , name : str , group : bool = False ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM , group )","title":"Proc"},{"location":"reference/dvc_task/proc/#dvc_task.proc.ManagedProcess","text":"Bases: AbstractContextManager Class to manage the specified process with redirected output. stdout and stderr will both be redirected to .out. Interactive processes (requiring stdin input) are currently unsupported. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 class ManagedProcess ( AbstractContextManager ): \"\"\"Class to manage the specified process with redirected output. stdout and stderr will both be redirected to <name>.out. Interactive processes (requiring stdin input) are currently unsupported. \"\"\" def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None def __enter__ ( self ): if self . _proc is None : self . run () return self def __exit__ ( self , * args , ** kwargs ): self . wait () def _close_fds ( self ): with self . _fd_stack : pass def _make_path ( self , path : str ) -> str : return os . path . join ( self . wdir , path ) if self . wdir else path @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) @property def info ( self ) -> \"ProcessInfo\" : \"\"\"Return process information.\"\"\" return ProcessInfo ( pid = self . pid , stdin = None , stdout = self . stdout_path , stderr = None , returncode = self . returncode , ) @property def pid ( self ) -> int : \"\"\"Return process PID. Raises: ValueError: Process is not running. \"\"\" if self . _proc is None : raise ValueError return self . _proc . pid def _make_wdir ( self ): if self . wdir : makedirs ( self . wdir , exist_ok = True ) def _dump ( self ): self . _make_wdir () self . info . dump ( self . info_path ) with open ( self . pidfile_path , \"w\" , encoding = \"utf-8\" ) as fobj : fobj . write ( str ( self . pid )) def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( # nosec B603 self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc except KeyboardInterrupt : pass self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid @classmethod def _spawn ( cls , * args , ** kwargs ): with cls ( * args , ** kwargs ): pass","title":"ManagedProcess"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.info","text":"Return process information.","title":"info"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.pid","text":"Return process PID. Raises: Type Description ValueError Process is not running.","title":"pid"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.__init__","text":"Construct a MangedProcess. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to be run. required env Optional [ Dict [ str , str ]] Optional environment variables. None wdir Optional [ str ] If specified, redirected output files will be placed in wdir . Defaults to current working directory. None name Optional [ str ] Name to use for this process, if not specified a UUID will be generated instead. None Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None","title":"__init__()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.info_path","text":"Return process information file path. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 118 119 120 121 @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" )","title":"info_path()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.pidfile_path","text":"Return process pidfile path. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 123 124 125 126 @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" )","title":"pidfile_path()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.run","text":"Run this process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( # nosec B603 self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise","title":"run()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.spawn","text":"Spawn a ManagedProcess command in the background. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid","title":"spawn()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.stdout_path","text":"Return redirected stdout path. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 113 114 115 116 @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" )","title":"stdout_path()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.wait","text":"Block until a process started with run has completed. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc except KeyboardInterrupt : pass self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode","title":"wait()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.ProcessInfo","text":"Process information. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 @dataclass class ProcessInfo : \"\"\"Process information.\"\"\" pid : int stdin : Optional [ str ] stdout : Optional [ str ] stderr : Optional [ str ] returncode : Optional [ int ] @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj )) def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" directory , file = os . path . split ( filename ) with tempfile . NamedTemporaryFile ( mode = \"w\" , encoding = \"utf-8\" , dir = directory , prefix = f \" { file } .\" , suffix = \".tmp\" , delete = False , ) as tmp : json . dump ( self . asdict (), tmp ) os . replace ( tmp . name , filename )","title":"ProcessInfo"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ProcessInfo.asdict","text":"Return this info as a dictionary. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 43 44 45 def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self )","title":"asdict()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ProcessInfo.dump","text":"Dump the process information into a file. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 47 48 49 50 51 52 53 54 55 56 57 58 59 def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" directory , file = os . path . split ( filename ) with tempfile . NamedTemporaryFile ( mode = \"w\" , encoding = \"utf-8\" , dir = directory , prefix = f \" { file } .\" , suffix = \".tmp\" , delete = False , ) as tmp : json . dump ( self . asdict (), tmp ) os . replace ( tmp . name , filename )","title":"dump()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ProcessInfo.from_dict","text":"Construct ProcessInfo from the specified dictionary. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 32 33 34 35 @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data )","title":"from_dict()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ProcessInfo.load","text":"Construct the process information from a file. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 37 38 39 40 41 @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj ))","title":"load()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.ProcessManager","text":"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 class ProcessManager : \"\"\"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. \"\"\" def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir def __iter__ ( self ) -> Generator [ str , None , None ]: if not os . path . exists ( self . wdir ): return yield from os . listdir ( self . wdir ) @reraise ( FileNotFoundError , KeyError ) def __getitem__ ( self , key : str ) -> \"ProcessInfo\" : info_path = self . _get_info_path ( key ) return ProcessInfo . load ( info_path ) @reraise ( FileNotFoundError , KeyError ) def __setitem__ ( self , key : str , value : \"ProcessInfo\" ): info_path = self . _get_info_path ( key ) value . dump ( info_path ) def __delitem__ ( self , key : str ) -> None : path = os . path . join ( self . wdir , key ) if os . path . exists ( path ): remove ( path ) def _get_info_path ( self , key : str ) -> str : return os . path . join ( self . wdir , key , f \" { key } .json\" ) def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) def send_signal ( self , name : str , sig : int , group : bool = False ): \"\"\"Send `signal` to the specified named process.\"\"\" try : process_info = self [ name ] except KeyError as exc : raise ProcessLookupError from exc if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : if sys . platform != \"win32\" and group : pgid = os . getpgid ( process_info . pid ) # pylint: disable=no-member os . killpg ( pgid , sig ) # pylint: disable=no-member else : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise else : raise ProcessLookupError def interrupt ( self , name : str , group : bool = True ): \"\"\"Send interrupt signal to specified named process\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . CTRL_C_EVENT , group # pylint: disable=no-member ) else : self . send_signal ( name , signal . SIGINT , group ) def terminate ( self , name : str , group : bool = False ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM , group ) def kill ( self , name : str , group : bool = False ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM , group ) else : self . send_signal ( name , signal . SIGKILL , group ) # pylint: disable=no-member def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset )","title":"ProcessManager"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.__init__","text":"Construct a ProcessManager Parameters: Name Type Description Default wdir Optional [ str ] Directory used for storing process information. Defaults to the current working directory. None Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir","title":"__init__()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.cleanup","text":"Remove stale (terminated) processes from this manager. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 194 195 196 197 198 199 200 def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue","title":"cleanup()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.follow","text":"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Parameters: Name Type Description Default name str Process name. required encoding Optional [ str ] Text encoding for redirected output. Defaults to locale.getpreferredencoding() . None sleep_interval int Sleep interval for follow iterations (when waiting for output). 1 Note Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset )","title":"follow()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.get","text":"Return the specified process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 65 66 67 68 69 70 def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default","title":"get()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.interrupt","text":"Send interrupt signal to specified named process Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 152 153 154 155 156 157 158 159 def interrupt ( self , name : str , group : bool = True ): \"\"\"Send interrupt signal to specified named process\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . CTRL_C_EVENT , group # pylint: disable=no-member ) else : self . send_signal ( name , signal . SIGINT , group )","title":"interrupt()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.kill","text":"Kill the specified named process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 165 166 167 168 169 170 def kill ( self , name : str , group : bool = False ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM , group ) else : self . send_signal ( name , signal . SIGKILL , group ) # pylint: disable=no-member","title":"kill()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.processes","text":"Iterate over managed processes. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 72 73 74 75 76 77 78 def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue","title":"processes()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.remove","text":"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if force is True`, otherwise an exception will be raised. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ]","title":"remove()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.run_signature","text":"Return signature for a task which runs a command in the background. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to run. required name Optional [ str ] Optional name to use for the spawned process. None task Optional [ str ] Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. None env Optional [ Dict [ str , str ]] Optional environment to be passed into the process. None immutable bool True if the returned Signature should be immutable. False Returns: Type Description Signature Celery signature for the run task. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , )","title":"run_signature()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.send_signal","text":"Send signal to the specified named process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def send_signal ( self , name : str , sig : int , group : bool = False ): \"\"\"Send `signal` to the specified named process.\"\"\" try : process_info = self [ name ] except KeyError as exc : raise ProcessLookupError from exc if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : if sys . platform != \"win32\" and group : pgid = os . getpgid ( process_info . pid ) # pylint: disable=no-member os . killpg ( pgid , sig ) # pylint: disable=no-member else : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise else : raise ProcessLookupError","title":"send_signal()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.terminate","text":"Terminate the specified named process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 161 162 163 def terminate ( self , name : str , group : bool = False ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM , group )","title":"terminate()"},{"location":"reference/dvc_task/proc/exceptions/","text":"Process exceptions. ProcessNotFoundError Bases: DvcTaskError Process does not exist. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/exceptions.py 12 13 14 15 16 class ProcessNotFoundError ( DvcTaskError ): \"\"\"Process does not exist.\"\"\" def __init__ ( self , name ): super () . __init__ ( f \"Managed process ' { name } ' does not exist.\" ) ProcessNotTerminatedError Bases: DvcTaskError Process is still running. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/exceptions.py 5 6 7 8 9 class ProcessNotTerminatedError ( DvcTaskError ): \"\"\"Process is still running.\"\"\" def __init__ ( self , name ): super () . __init__ ( f \"Managed process ' { name } ' has not been terminated.\" ) TimeoutExpired Bases: DvcTaskError Process timeout expired. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/exceptions.py 19 20 21 22 23 24 25 class TimeoutExpired ( DvcTaskError ): \"\"\"Process timeout expired.\"\"\" def __init__ ( self , cmd , timeout ): super () . __init__ ( f \"' { cmd } ' did not complete before timeout ' { timeout } '\" ) self . cmd = cmd self . timeout = timeout UnsupportedSignalError Bases: DvcTaskError Unsupported process signal. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/exceptions.py 28 29 30 31 32 class UnsupportedSignalError ( DvcTaskError ): \"\"\"Unsupported process signal.\"\"\" def __init__ ( self , sig ): super () . __init__ ( f \"Unsupported signal: { sig } \" )","title":"Exceptions"},{"location":"reference/dvc_task/proc/exceptions/#dvc_task.proc.exceptions.ProcessNotFoundError","text":"Bases: DvcTaskError Process does not exist. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/exceptions.py 12 13 14 15 16 class ProcessNotFoundError ( DvcTaskError ): \"\"\"Process does not exist.\"\"\" def __init__ ( self , name ): super () . __init__ ( f \"Managed process ' { name } ' does not exist.\" )","title":"ProcessNotFoundError"},{"location":"reference/dvc_task/proc/exceptions/#dvc_task.proc.exceptions.ProcessNotTerminatedError","text":"Bases: DvcTaskError Process is still running. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/exceptions.py 5 6 7 8 9 class ProcessNotTerminatedError ( DvcTaskError ): \"\"\"Process is still running.\"\"\" def __init__ ( self , name ): super () . __init__ ( f \"Managed process ' { name } ' has not been terminated.\" )","title":"ProcessNotTerminatedError"},{"location":"reference/dvc_task/proc/exceptions/#dvc_task.proc.exceptions.TimeoutExpired","text":"Bases: DvcTaskError Process timeout expired. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/exceptions.py 19 20 21 22 23 24 25 class TimeoutExpired ( DvcTaskError ): \"\"\"Process timeout expired.\"\"\" def __init__ ( self , cmd , timeout ): super () . __init__ ( f \"' { cmd } ' did not complete before timeout ' { timeout } '\" ) self . cmd = cmd self . timeout = timeout","title":"TimeoutExpired"},{"location":"reference/dvc_task/proc/exceptions/#dvc_task.proc.exceptions.UnsupportedSignalError","text":"Bases: DvcTaskError Unsupported process signal. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/exceptions.py 28 29 30 31 32 class UnsupportedSignalError ( DvcTaskError ): \"\"\"Unsupported process signal.\"\"\" def __init__ ( self , sig ): super () . __init__ ( f \"Unsupported signal: { sig } \" )","title":"UnsupportedSignalError"},{"location":"reference/dvc_task/proc/manager/","text":"Serverless process manager. ProcessManager Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 class ProcessManager : \"\"\"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. \"\"\" def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir def __iter__ ( self ) -> Generator [ str , None , None ]: if not os . path . exists ( self . wdir ): return yield from os . listdir ( self . wdir ) @reraise ( FileNotFoundError , KeyError ) def __getitem__ ( self , key : str ) -> \"ProcessInfo\" : info_path = self . _get_info_path ( key ) return ProcessInfo . load ( info_path ) @reraise ( FileNotFoundError , KeyError ) def __setitem__ ( self , key : str , value : \"ProcessInfo\" ): info_path = self . _get_info_path ( key ) value . dump ( info_path ) def __delitem__ ( self , key : str ) -> None : path = os . path . join ( self . wdir , key ) if os . path . exists ( path ): remove ( path ) def _get_info_path ( self , key : str ) -> str : return os . path . join ( self . wdir , key , f \" { key } .json\" ) def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) def send_signal ( self , name : str , sig : int , group : bool = False ): \"\"\"Send `signal` to the specified named process.\"\"\" try : process_info = self [ name ] except KeyError as exc : raise ProcessLookupError from exc if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : if sys . platform != \"win32\" and group : pgid = os . getpgid ( process_info . pid ) # pylint: disable=no-member os . killpg ( pgid , sig ) # pylint: disable=no-member else : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise else : raise ProcessLookupError def interrupt ( self , name : str , group : bool = True ): \"\"\"Send interrupt signal to specified named process\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . CTRL_C_EVENT , group # pylint: disable=no-member ) else : self . send_signal ( name , signal . SIGINT , group ) def terminate ( self , name : str , group : bool = False ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM , group ) def kill ( self , name : str , group : bool = False ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM , group ) else : self . send_signal ( name , signal . SIGKILL , group ) # pylint: disable=no-member def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset ) __init__ ( wdir = None ) Construct a ProcessManager Parameters: Name Type Description Default wdir Optional [ str ] Directory used for storing process information. Defaults to the current working directory. None Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir cleanup ( force = False ) Remove stale (terminated) processes from this manager. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 194 195 196 197 198 199 200 def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue follow ( name , encoding = None , sleep_interval = 1 ) Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Parameters: Name Type Description Default name str Process name. required encoding Optional [ str ] Text encoding for redirected output. Defaults to locale.getpreferredencoding() . None sleep_interval int Sleep interval for follow iterations (when waiting for output). 1 Note Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset ) get ( key , default = None ) Return the specified process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 65 66 67 68 69 70 def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default interrupt ( name , group = True ) Send interrupt signal to specified named process Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 152 153 154 155 156 157 158 159 def interrupt ( self , name : str , group : bool = True ): \"\"\"Send interrupt signal to specified named process\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . CTRL_C_EVENT , group # pylint: disable=no-member ) else : self . send_signal ( name , signal . SIGINT , group ) kill ( name , group = False ) Kill the specified named process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 165 166 167 168 169 170 def kill ( self , name : str , group : bool = False ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM , group ) else : self . send_signal ( name , signal . SIGKILL , group ) # pylint: disable=no-member processes () Iterate over managed processes. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 72 73 74 75 76 77 78 def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue remove ( name , force = False ) Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if force is True`, otherwise an exception will be raised. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] run_signature ( args , name = None , task = None , env = None , immutable = False ) Return signature for a task which runs a command in the background. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to run. required name Optional [ str ] Optional name to use for the spawned process. None task Optional [ str ] Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. None env Optional [ Dict [ str , str ]] Optional environment to be passed into the process. None immutable bool True if the returned Signature should be immutable. False Returns: Type Description Signature Celery signature for the run task. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) send_signal ( name , sig , group = False ) Send signal to the specified named process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def send_signal ( self , name : str , sig : int , group : bool = False ): \"\"\"Send `signal` to the specified named process.\"\"\" try : process_info = self [ name ] except KeyError as exc : raise ProcessLookupError from exc if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : if sys . platform != \"win32\" and group : pgid = os . getpgid ( process_info . pid ) # pylint: disable=no-member os . killpg ( pgid , sig ) # pylint: disable=no-member else : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise else : raise ProcessLookupError terminate ( name , group = False ) Terminate the specified named process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 161 162 163 def terminate ( self , name : str , group : bool = False ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM , group )","title":"Manager"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager","text":"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 class ProcessManager : \"\"\"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. \"\"\" def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir def __iter__ ( self ) -> Generator [ str , None , None ]: if not os . path . exists ( self . wdir ): return yield from os . listdir ( self . wdir ) @reraise ( FileNotFoundError , KeyError ) def __getitem__ ( self , key : str ) -> \"ProcessInfo\" : info_path = self . _get_info_path ( key ) return ProcessInfo . load ( info_path ) @reraise ( FileNotFoundError , KeyError ) def __setitem__ ( self , key : str , value : \"ProcessInfo\" ): info_path = self . _get_info_path ( key ) value . dump ( info_path ) def __delitem__ ( self , key : str ) -> None : path = os . path . join ( self . wdir , key ) if os . path . exists ( path ): remove ( path ) def _get_info_path ( self , key : str ) -> str : return os . path . join ( self . wdir , key , f \" { key } .json\" ) def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) def send_signal ( self , name : str , sig : int , group : bool = False ): \"\"\"Send `signal` to the specified named process.\"\"\" try : process_info = self [ name ] except KeyError as exc : raise ProcessLookupError from exc if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : if sys . platform != \"win32\" and group : pgid = os . getpgid ( process_info . pid ) # pylint: disable=no-member os . killpg ( pgid , sig ) # pylint: disable=no-member else : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise else : raise ProcessLookupError def interrupt ( self , name : str , group : bool = True ): \"\"\"Send interrupt signal to specified named process\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . CTRL_C_EVENT , group # pylint: disable=no-member ) else : self . send_signal ( name , signal . SIGINT , group ) def terminate ( self , name : str , group : bool = False ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM , group ) def kill ( self , name : str , group : bool = False ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM , group ) else : self . send_signal ( name , signal . SIGKILL , group ) # pylint: disable=no-member def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset )","title":"ProcessManager"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.__init__","text":"Construct a ProcessManager Parameters: Name Type Description Default wdir Optional [ str ] Directory used for storing process information. Defaults to the current working directory. None Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir","title":"__init__()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.cleanup","text":"Remove stale (terminated) processes from this manager. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 194 195 196 197 198 199 200 def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue","title":"cleanup()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.follow","text":"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Parameters: Name Type Description Default name str Process name. required encoding Optional [ str ] Text encoding for redirected output. Defaults to locale.getpreferredencoding() . None sleep_interval int Sleep interval for follow iterations (when waiting for output). 1 Note Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset )","title":"follow()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.get","text":"Return the specified process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 65 66 67 68 69 70 def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default","title":"get()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.interrupt","text":"Send interrupt signal to specified named process Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 152 153 154 155 156 157 158 159 def interrupt ( self , name : str , group : bool = True ): \"\"\"Send interrupt signal to specified named process\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . CTRL_C_EVENT , group # pylint: disable=no-member ) else : self . send_signal ( name , signal . SIGINT , group )","title":"interrupt()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.kill","text":"Kill the specified named process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 165 166 167 168 169 170 def kill ( self , name : str , group : bool = False ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM , group ) else : self . send_signal ( name , signal . SIGKILL , group ) # pylint: disable=no-member","title":"kill()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.processes","text":"Iterate over managed processes. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 72 73 74 75 76 77 78 def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue","title":"processes()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.remove","text":"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if force is True`, otherwise an exception will be raised. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ]","title":"remove()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.run_signature","text":"Return signature for a task which runs a command in the background. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to run. required name Optional [ str ] Optional name to use for the spawned process. None task Optional [ str ] Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. None env Optional [ Dict [ str , str ]] Optional environment to be passed into the process. None immutable bool True if the returned Signature should be immutable. False Returns: Type Description Signature Celery signature for the run task. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , )","title":"run_signature()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.send_signal","text":"Send signal to the specified named process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def send_signal ( self , name : str , sig : int , group : bool = False ): \"\"\"Send `signal` to the specified named process.\"\"\" try : process_info = self [ name ] except KeyError as exc : raise ProcessLookupError from exc if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : if sys . platform != \"win32\" and group : pgid = os . getpgid ( process_info . pid ) # pylint: disable=no-member os . killpg ( pgid , sig ) # pylint: disable=no-member else : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise else : raise ProcessLookupError","title":"send_signal()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.terminate","text":"Terminate the specified named process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/manager.py 161 162 163 def terminate ( self , name : str , group : bool = False ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM , group )","title":"terminate()"},{"location":"reference/dvc_task/proc/process/","text":"Managed process module. ManagedProcess Bases: AbstractContextManager Class to manage the specified process with redirected output. stdout and stderr will both be redirected to .out. Interactive processes (requiring stdin input) are currently unsupported. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 class ManagedProcess ( AbstractContextManager ): \"\"\"Class to manage the specified process with redirected output. stdout and stderr will both be redirected to <name>.out. Interactive processes (requiring stdin input) are currently unsupported. \"\"\" def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None def __enter__ ( self ): if self . _proc is None : self . run () return self def __exit__ ( self , * args , ** kwargs ): self . wait () def _close_fds ( self ): with self . _fd_stack : pass def _make_path ( self , path : str ) -> str : return os . path . join ( self . wdir , path ) if self . wdir else path @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) @property def info ( self ) -> \"ProcessInfo\" : \"\"\"Return process information.\"\"\" return ProcessInfo ( pid = self . pid , stdin = None , stdout = self . stdout_path , stderr = None , returncode = self . returncode , ) @property def pid ( self ) -> int : \"\"\"Return process PID. Raises: ValueError: Process is not running. \"\"\" if self . _proc is None : raise ValueError return self . _proc . pid def _make_wdir ( self ): if self . wdir : makedirs ( self . wdir , exist_ok = True ) def _dump ( self ): self . _make_wdir () self . info . dump ( self . info_path ) with open ( self . pidfile_path , \"w\" , encoding = \"utf-8\" ) as fobj : fobj . write ( str ( self . pid )) def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( # nosec B603 self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc except KeyboardInterrupt : pass self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid @classmethod def _spawn ( cls , * args , ** kwargs ): with cls ( * args , ** kwargs ): pass info : ProcessInfo property Return process information. pid : int property Return process PID. Raises: Type Description ValueError Process is not running. __init__ ( args , env = None , wdir = None , name = None ) Construct a MangedProcess. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to be run. required env Optional [ Dict [ str , str ]] Optional environment variables. None wdir Optional [ str ] If specified, redirected output files will be placed in wdir . Defaults to current working directory. None name Optional [ str ] Name to use for this process, if not specified a UUID will be generated instead. None Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None info_path () Return process information file path. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 118 119 120 121 @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) pidfile_path () Return process pidfile path. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 123 124 125 126 @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) run () Run this process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( # nosec B603 self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise spawn ( args , kwargs ) classmethod Spawn a ManagedProcess command in the background. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid stdout_path () Return redirected stdout path. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 113 114 115 116 @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) wait ( timeout = None ) Block until a process started with run has completed. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc except KeyboardInterrupt : pass self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode ProcessInfo dataclass Process information. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 @dataclass class ProcessInfo : \"\"\"Process information.\"\"\" pid : int stdin : Optional [ str ] stdout : Optional [ str ] stderr : Optional [ str ] returncode : Optional [ int ] @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj )) def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" directory , file = os . path . split ( filename ) with tempfile . NamedTemporaryFile ( mode = \"w\" , encoding = \"utf-8\" , dir = directory , prefix = f \" { file } .\" , suffix = \".tmp\" , delete = False , ) as tmp : json . dump ( self . asdict (), tmp ) os . replace ( tmp . name , filename ) asdict () Return this info as a dictionary. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 43 44 45 def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) dump ( filename ) Dump the process information into a file. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 47 48 49 50 51 52 53 54 55 56 57 58 59 def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" directory , file = os . path . split ( filename ) with tempfile . NamedTemporaryFile ( mode = \"w\" , encoding = \"utf-8\" , dir = directory , prefix = f \" { file } .\" , suffix = \".tmp\" , delete = False , ) as tmp : json . dump ( self . asdict (), tmp ) os . replace ( tmp . name , filename ) from_dict ( data ) classmethod Construct ProcessInfo from the specified dictionary. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 32 33 34 35 @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) load ( filename ) classmethod Construct the process information from a file. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 37 38 39 40 41 @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj ))","title":"Process"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess","text":"Bases: AbstractContextManager Class to manage the specified process with redirected output. stdout and stderr will both be redirected to .out. Interactive processes (requiring stdin input) are currently unsupported. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 class ManagedProcess ( AbstractContextManager ): \"\"\"Class to manage the specified process with redirected output. stdout and stderr will both be redirected to <name>.out. Interactive processes (requiring stdin input) are currently unsupported. \"\"\" def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None def __enter__ ( self ): if self . _proc is None : self . run () return self def __exit__ ( self , * args , ** kwargs ): self . wait () def _close_fds ( self ): with self . _fd_stack : pass def _make_path ( self , path : str ) -> str : return os . path . join ( self . wdir , path ) if self . wdir else path @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) @property def info ( self ) -> \"ProcessInfo\" : \"\"\"Return process information.\"\"\" return ProcessInfo ( pid = self . pid , stdin = None , stdout = self . stdout_path , stderr = None , returncode = self . returncode , ) @property def pid ( self ) -> int : \"\"\"Return process PID. Raises: ValueError: Process is not running. \"\"\" if self . _proc is None : raise ValueError return self . _proc . pid def _make_wdir ( self ): if self . wdir : makedirs ( self . wdir , exist_ok = True ) def _dump ( self ): self . _make_wdir () self . info . dump ( self . info_path ) with open ( self . pidfile_path , \"w\" , encoding = \"utf-8\" ) as fobj : fobj . write ( str ( self . pid )) def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( # nosec B603 self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc except KeyboardInterrupt : pass self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid @classmethod def _spawn ( cls , * args , ** kwargs ): with cls ( * args , ** kwargs ): pass","title":"ManagedProcess"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.info","text":"Return process information.","title":"info"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.pid","text":"Return process PID. Raises: Type Description ValueError Process is not running.","title":"pid"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.__init__","text":"Construct a MangedProcess. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to be run. required env Optional [ Dict [ str , str ]] Optional environment variables. None wdir Optional [ str ] If specified, redirected output files will be placed in wdir . Defaults to current working directory. None name Optional [ str ] Name to use for this process, if not specified a UUID will be generated instead. None Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None","title":"__init__()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.info_path","text":"Return process information file path. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 118 119 120 121 @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" )","title":"info_path()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.pidfile_path","text":"Return process pidfile path. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 123 124 125 126 @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" )","title":"pidfile_path()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.run","text":"Run this process. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( # nosec B603 self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise","title":"run()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.spawn","text":"Spawn a ManagedProcess command in the background. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid","title":"spawn()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.stdout_path","text":"Return redirected stdout path. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 113 114 115 116 @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" )","title":"stdout_path()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.wait","text":"Block until a process started with run has completed. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc except KeyboardInterrupt : pass self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode","title":"wait()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ProcessInfo","text":"Process information. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 @dataclass class ProcessInfo : \"\"\"Process information.\"\"\" pid : int stdin : Optional [ str ] stdout : Optional [ str ] stderr : Optional [ str ] returncode : Optional [ int ] @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj )) def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" directory , file = os . path . split ( filename ) with tempfile . NamedTemporaryFile ( mode = \"w\" , encoding = \"utf-8\" , dir = directory , prefix = f \" { file } .\" , suffix = \".tmp\" , delete = False , ) as tmp : json . dump ( self . asdict (), tmp ) os . replace ( tmp . name , filename )","title":"ProcessInfo"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ProcessInfo.asdict","text":"Return this info as a dictionary. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 43 44 45 def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self )","title":"asdict()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ProcessInfo.dump","text":"Dump the process information into a file. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 47 48 49 50 51 52 53 54 55 56 57 58 59 def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" directory , file = os . path . split ( filename ) with tempfile . NamedTemporaryFile ( mode = \"w\" , encoding = \"utf-8\" , dir = directory , prefix = f \" { file } .\" , suffix = \".tmp\" , delete = False , ) as tmp : json . dump ( self . asdict (), tmp ) os . replace ( tmp . name , filename )","title":"dump()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ProcessInfo.from_dict","text":"Construct ProcessInfo from the specified dictionary. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 32 33 34 35 @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data )","title":"from_dict()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ProcessInfo.load","text":"Construct the process information from a file. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/process.py 37 38 39 40 41 @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj ))","title":"load()"},{"location":"reference/dvc_task/proc/tasks/","text":"Celery tasks. run ( self , args , kwargs ) Run a command inside a celery task. Accepts the same arguments as proc.process.ManagedProcess . Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/tasks.py 9 10 11 12 13 14 15 16 17 18 19 @shared_task ( bind = True ) def run ( # pylint: disable=unused-argument self , * args : Any , ** kwargs : Any ) -> Dict [ str , Any ]: \"\"\"Run a command inside a celery task. Accepts the same arguments as `proc.process.ManagedProcess`. \"\"\" with ManagedProcess ( * args , ** kwargs ) as proc : pass return proc . info . asdict ()","title":"Tasks"},{"location":"reference/dvc_task/proc/tasks/#dvc_task.proc.tasks.run","text":"Run a command inside a celery task. Accepts the same arguments as proc.process.ManagedProcess . Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/proc/tasks.py 9 10 11 12 13 14 15 16 17 18 19 @shared_task ( bind = True ) def run ( # pylint: disable=unused-argument self , * args : Any , ** kwargs : Any ) -> Dict [ str , Any ]: \"\"\"Run a command inside a celery task. Accepts the same arguments as `proc.process.ManagedProcess`. \"\"\" with ManagedProcess ( * args , ** kwargs ) as proc : pass return proc . info . asdict ()","title":"run()"},{"location":"reference/dvc_task/worker/","text":"DVC Task worker factories. TemporaryWorker Temporary worker that automatically shuts down when queue is empty. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 class TemporaryWorker : \"\"\"Temporary worker that automatically shuts down when queue is empty.\"\"\" def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs def ping ( self , name : str , timeout : float = 1.0 ) -> Optional [ List [ Dict [ str , Any ]]]: \"\"\"Ping the specified worker.\"\"\" return self . _ping ( destination = [ default_nodename ( name )], timeout = timeout ) def _ping ( self , * , destination : Optional [ List [ str ]] = None , timeout : float = 1.0 ) -> Optional [ List [ Dict [ str , Any ]]]: return self . app . control . ping ( destination = destination , timeout = timeout ) def start ( self , name : str , fsapp_clean : bool = False ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. fsapp_clean: Automatically cleanup FSApp broker on shutdown. Has no effect unless app is an FSApp instance. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . ping ( name ): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,), ) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv ) if fsapp_clean and isinstance ( self . app , FSApp ): # type: ignore[unreachable] logger . info ( \"cleaning up FSApp broker.\" ) self . app . clean () logger . info ( \"done\" ) @staticmethod def _parse_config ( config : Mapping [ str , Any ]) -> List [ str ]: loglevel = config . get ( \"loglevel\" , \"info\" ) argv = [ f \"--loglevel= { loglevel } \" ] for key in ( \"hostname\" , \"pool\" , \"concurrency\" , \"prefetch_multiplier\" ): value = config . get ( key ) if value : argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } = { value } \" ) for key in ( \"without_heartbeat\" , \"without_mingle\" , \"without_gossip\" , ): if config . get ( key ): argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } \" ) if config . get ( \"task_events\" ): argv . append ( \"-E\" ) return argv def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" nodename = default_nodename ( name ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () if isinstance ( self . app , FSApp ): yield from self . app . iter_queued () logger . debug ( \"monitor: watching celery worker ' %s '\" , nodename ) while True : time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ], limit = 1 , ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) break logger . debug ( \"monitor: sending shutdown to ' %s '.\" , nodename ) self . app . control . shutdown () logger . debug ( \"monitor: done\" ) __init__ ( app , timeout = 60 , kwargs ) Construct a worker. Parameters: Name Type Description Default app Celery Celery application instance. required timeout int Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. 60 Additional keyword arguments will be passed as celery worker configuration. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs monitor ( name ) Monitor the worker and stop it when the queue is empty. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" nodename = default_nodename ( name ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () if isinstance ( self . app , FSApp ): yield from self . app . iter_queued () logger . debug ( \"monitor: watching celery worker ' %s '\" , nodename ) while True : time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ], limit = 1 , ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) break logger . debug ( \"monitor: sending shutdown to ' %s '.\" , nodename ) self . app . control . shutdown () logger . debug ( \"monitor: done\" ) ping ( name , timeout = 1.0 ) Ping the specified worker. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 39 40 41 def ping ( self , name : str , timeout : float = 1.0 ) -> Optional [ List [ Dict [ str , Any ]]]: \"\"\"Ping the specified worker.\"\"\" return self . _ping ( destination = [ default_nodename ( name )], timeout = timeout ) start ( name , fsapp_clean = False ) Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Parameters: Name Type Description Default name str Celery worker name. required fsapp_clean bool Automatically cleanup FSApp broker on shutdown. Has no effect unless app is an FSApp instance. False Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def start ( self , name : str , fsapp_clean : bool = False ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. fsapp_clean: Automatically cleanup FSApp broker on shutdown. Has no effect unless app is an FSApp instance. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . ping ( name ): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,), ) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv ) if fsapp_clean and isinstance ( self . app , FSApp ): # type: ignore[unreachable] logger . info ( \"cleaning up FSApp broker.\" ) self . app . clean () logger . info ( \"done\" )","title":"Worker"},{"location":"reference/dvc_task/worker/#dvc_task.worker.TemporaryWorker","text":"Temporary worker that automatically shuts down when queue is empty. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 class TemporaryWorker : \"\"\"Temporary worker that automatically shuts down when queue is empty.\"\"\" def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs def ping ( self , name : str , timeout : float = 1.0 ) -> Optional [ List [ Dict [ str , Any ]]]: \"\"\"Ping the specified worker.\"\"\" return self . _ping ( destination = [ default_nodename ( name )], timeout = timeout ) def _ping ( self , * , destination : Optional [ List [ str ]] = None , timeout : float = 1.0 ) -> Optional [ List [ Dict [ str , Any ]]]: return self . app . control . ping ( destination = destination , timeout = timeout ) def start ( self , name : str , fsapp_clean : bool = False ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. fsapp_clean: Automatically cleanup FSApp broker on shutdown. Has no effect unless app is an FSApp instance. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . ping ( name ): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,), ) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv ) if fsapp_clean and isinstance ( self . app , FSApp ): # type: ignore[unreachable] logger . info ( \"cleaning up FSApp broker.\" ) self . app . clean () logger . info ( \"done\" ) @staticmethod def _parse_config ( config : Mapping [ str , Any ]) -> List [ str ]: loglevel = config . get ( \"loglevel\" , \"info\" ) argv = [ f \"--loglevel= { loglevel } \" ] for key in ( \"hostname\" , \"pool\" , \"concurrency\" , \"prefetch_multiplier\" ): value = config . get ( key ) if value : argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } = { value } \" ) for key in ( \"without_heartbeat\" , \"without_mingle\" , \"without_gossip\" , ): if config . get ( key ): argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } \" ) if config . get ( \"task_events\" ): argv . append ( \"-E\" ) return argv def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" nodename = default_nodename ( name ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () if isinstance ( self . app , FSApp ): yield from self . app . iter_queued () logger . debug ( \"monitor: watching celery worker ' %s '\" , nodename ) while True : time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ], limit = 1 , ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) break logger . debug ( \"monitor: sending shutdown to ' %s '.\" , nodename ) self . app . control . shutdown () logger . debug ( \"monitor: done\" )","title":"TemporaryWorker"},{"location":"reference/dvc_task/worker/#dvc_task.worker.temporary.TemporaryWorker.__init__","text":"Construct a worker. Parameters: Name Type Description Default app Celery Celery application instance. required timeout int Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. 60 Additional keyword arguments will be passed as celery worker configuration. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs","title":"__init__()"},{"location":"reference/dvc_task/worker/#dvc_task.worker.temporary.TemporaryWorker.monitor","text":"Monitor the worker and stop it when the queue is empty. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" nodename = default_nodename ( name ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () if isinstance ( self . app , FSApp ): yield from self . app . iter_queued () logger . debug ( \"monitor: watching celery worker ' %s '\" , nodename ) while True : time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ], limit = 1 , ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) break logger . debug ( \"monitor: sending shutdown to ' %s '.\" , nodename ) self . app . control . shutdown () logger . debug ( \"monitor: done\" )","title":"monitor()"},{"location":"reference/dvc_task/worker/#dvc_task.worker.temporary.TemporaryWorker.ping","text":"Ping the specified worker. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 39 40 41 def ping ( self , name : str , timeout : float = 1.0 ) -> Optional [ List [ Dict [ str , Any ]]]: \"\"\"Ping the specified worker.\"\"\" return self . _ping ( destination = [ default_nodename ( name )], timeout = timeout )","title":"ping()"},{"location":"reference/dvc_task/worker/#dvc_task.worker.temporary.TemporaryWorker.start","text":"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Parameters: Name Type Description Default name str Celery worker name. required fsapp_clean bool Automatically cleanup FSApp broker on shutdown. Has no effect unless app is an FSApp instance. False Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def start ( self , name : str , fsapp_clean : bool = False ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. fsapp_clean: Automatically cleanup FSApp broker on shutdown. Has no effect unless app is an FSApp instance. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . ping ( name ): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,), ) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv ) if fsapp_clean and isinstance ( self . app , FSApp ): # type: ignore[unreachable] logger . info ( \"cleaning up FSApp broker.\" ) self . app . clean () logger . info ( \"done\" )","title":"start()"},{"location":"reference/dvc_task/worker/temporary/","text":"Temporary worker module. TemporaryWorker Temporary worker that automatically shuts down when queue is empty. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 class TemporaryWorker : \"\"\"Temporary worker that automatically shuts down when queue is empty.\"\"\" def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs def ping ( self , name : str , timeout : float = 1.0 ) -> Optional [ List [ Dict [ str , Any ]]]: \"\"\"Ping the specified worker.\"\"\" return self . _ping ( destination = [ default_nodename ( name )], timeout = timeout ) def _ping ( self , * , destination : Optional [ List [ str ]] = None , timeout : float = 1.0 ) -> Optional [ List [ Dict [ str , Any ]]]: return self . app . control . ping ( destination = destination , timeout = timeout ) def start ( self , name : str , fsapp_clean : bool = False ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. fsapp_clean: Automatically cleanup FSApp broker on shutdown. Has no effect unless app is an FSApp instance. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . ping ( name ): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,), ) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv ) if fsapp_clean and isinstance ( self . app , FSApp ): # type: ignore[unreachable] logger . info ( \"cleaning up FSApp broker.\" ) self . app . clean () logger . info ( \"done\" ) @staticmethod def _parse_config ( config : Mapping [ str , Any ]) -> List [ str ]: loglevel = config . get ( \"loglevel\" , \"info\" ) argv = [ f \"--loglevel= { loglevel } \" ] for key in ( \"hostname\" , \"pool\" , \"concurrency\" , \"prefetch_multiplier\" ): value = config . get ( key ) if value : argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } = { value } \" ) for key in ( \"without_heartbeat\" , \"without_mingle\" , \"without_gossip\" , ): if config . get ( key ): argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } \" ) if config . get ( \"task_events\" ): argv . append ( \"-E\" ) return argv def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" nodename = default_nodename ( name ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () if isinstance ( self . app , FSApp ): yield from self . app . iter_queued () logger . debug ( \"monitor: watching celery worker ' %s '\" , nodename ) while True : time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ], limit = 1 , ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) break logger . debug ( \"monitor: sending shutdown to ' %s '.\" , nodename ) self . app . control . shutdown () logger . debug ( \"monitor: done\" ) __init__ ( app , timeout = 60 , kwargs ) Construct a worker. Parameters: Name Type Description Default app Celery Celery application instance. required timeout int Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. 60 Additional keyword arguments will be passed as celery worker configuration. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs monitor ( name ) Monitor the worker and stop it when the queue is empty. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" nodename = default_nodename ( name ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () if isinstance ( self . app , FSApp ): yield from self . app . iter_queued () logger . debug ( \"monitor: watching celery worker ' %s '\" , nodename ) while True : time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ], limit = 1 , ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) break logger . debug ( \"monitor: sending shutdown to ' %s '.\" , nodename ) self . app . control . shutdown () logger . debug ( \"monitor: done\" ) ping ( name , timeout = 1.0 ) Ping the specified worker. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 39 40 41 def ping ( self , name : str , timeout : float = 1.0 ) -> Optional [ List [ Dict [ str , Any ]]]: \"\"\"Ping the specified worker.\"\"\" return self . _ping ( destination = [ default_nodename ( name )], timeout = timeout ) start ( name , fsapp_clean = False ) Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Parameters: Name Type Description Default name str Celery worker name. required fsapp_clean bool Automatically cleanup FSApp broker on shutdown. Has no effect unless app is an FSApp instance. False Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def start ( self , name : str , fsapp_clean : bool = False ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. fsapp_clean: Automatically cleanup FSApp broker on shutdown. Has no effect unless app is an FSApp instance. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . ping ( name ): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,), ) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv ) if fsapp_clean and isinstance ( self . app , FSApp ): # type: ignore[unreachable] logger . info ( \"cleaning up FSApp broker.\" ) self . app . clean () logger . info ( \"done\" )","title":"Temporary"},{"location":"reference/dvc_task/worker/temporary/#dvc_task.worker.temporary.TemporaryWorker","text":"Temporary worker that automatically shuts down when queue is empty. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 class TemporaryWorker : \"\"\"Temporary worker that automatically shuts down when queue is empty.\"\"\" def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs def ping ( self , name : str , timeout : float = 1.0 ) -> Optional [ List [ Dict [ str , Any ]]]: \"\"\"Ping the specified worker.\"\"\" return self . _ping ( destination = [ default_nodename ( name )], timeout = timeout ) def _ping ( self , * , destination : Optional [ List [ str ]] = None , timeout : float = 1.0 ) -> Optional [ List [ Dict [ str , Any ]]]: return self . app . control . ping ( destination = destination , timeout = timeout ) def start ( self , name : str , fsapp_clean : bool = False ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. fsapp_clean: Automatically cleanup FSApp broker on shutdown. Has no effect unless app is an FSApp instance. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . ping ( name ): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,), ) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv ) if fsapp_clean and isinstance ( self . app , FSApp ): # type: ignore[unreachable] logger . info ( \"cleaning up FSApp broker.\" ) self . app . clean () logger . info ( \"done\" ) @staticmethod def _parse_config ( config : Mapping [ str , Any ]) -> List [ str ]: loglevel = config . get ( \"loglevel\" , \"info\" ) argv = [ f \"--loglevel= { loglevel } \" ] for key in ( \"hostname\" , \"pool\" , \"concurrency\" , \"prefetch_multiplier\" ): value = config . get ( key ) if value : argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } = { value } \" ) for key in ( \"without_heartbeat\" , \"without_mingle\" , \"without_gossip\" , ): if config . get ( key ): argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } \" ) if config . get ( \"task_events\" ): argv . append ( \"-E\" ) return argv def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" nodename = default_nodename ( name ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () if isinstance ( self . app , FSApp ): yield from self . app . iter_queued () logger . debug ( \"monitor: watching celery worker ' %s '\" , nodename ) while True : time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ], limit = 1 , ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) break logger . debug ( \"monitor: sending shutdown to ' %s '.\" , nodename ) self . app . control . shutdown () logger . debug ( \"monitor: done\" )","title":"TemporaryWorker"},{"location":"reference/dvc_task/worker/temporary/#dvc_task.worker.temporary.TemporaryWorker.__init__","text":"Construct a worker. Parameters: Name Type Description Default app Celery Celery application instance. required timeout int Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. 60 Additional keyword arguments will be passed as celery worker configuration. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs","title":"__init__()"},{"location":"reference/dvc_task/worker/temporary/#dvc_task.worker.temporary.TemporaryWorker.monitor","text":"Monitor the worker and stop it when the queue is empty. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" nodename = default_nodename ( name ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () if isinstance ( self . app , FSApp ): yield from self . app . iter_queued () logger . debug ( \"monitor: watching celery worker ' %s '\" , nodename ) while True : time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ], limit = 1 , ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) break logger . debug ( \"monitor: sending shutdown to ' %s '.\" , nodename ) self . app . control . shutdown () logger . debug ( \"monitor: done\" )","title":"monitor()"},{"location":"reference/dvc_task/worker/temporary/#dvc_task.worker.temporary.TemporaryWorker.ping","text":"Ping the specified worker. Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 39 40 41 def ping ( self , name : str , timeout : float = 1.0 ) -> Optional [ List [ Dict [ str , Any ]]]: \"\"\"Ping the specified worker.\"\"\" return self . _ping ( destination = [ default_nodename ( name )], timeout = timeout )","title":"ping()"},{"location":"reference/dvc_task/worker/temporary/#dvc_task.worker.temporary.TemporaryWorker.start","text":"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Parameters: Name Type Description Default name str Celery worker name. required fsapp_clean bool Automatically cleanup FSApp broker on shutdown. Has no effect unless app is an FSApp instance. False Source code in /opt/hostedtoolcache/Python/3.10.11/x64/lib/python3.10/site-packages/dvc_task/worker/temporary.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def start ( self , name : str , fsapp_clean : bool = False ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. fsapp_clean: Automatically cleanup FSApp broker on shutdown. Has no effect unless app is an FSApp instance. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . ping ( name ): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,), ) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv ) if fsapp_clean and isinstance ( self . app , FSApp ): # type: ignore[unreachable] logger . info ( \"cleaning up FSApp broker.\" ) self . app . clean () logger . info ( \"done\" )","title":"start()"}]}