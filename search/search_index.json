{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Dvc Task API Reference","title":"Welcome to Dvc Task"},{"location":"#welcome-to-dvc-task","text":"API Reference","title":"Welcome to Dvc Task"},{"location":"reference/dvc_task/","text":"DVC Task.","title":"Dvc task"},{"location":"reference/dvc_task/exceptions/","text":"Exception classes. DvcTaskError Bases: Exception Base DVC Task exception. Source code in dvc_task/exceptions.py 4 5 class DvcTaskError ( Exception ): \"\"\"Base DVC Task exception.\"\"\"","title":"Exceptions"},{"location":"reference/dvc_task/exceptions/#dvc_task.exceptions.DvcTaskError","text":"Bases: Exception Base DVC Task exception. Source code in dvc_task/exceptions.py 4 5 class DvcTaskError ( Exception ): \"\"\"Base DVC Task exception.\"\"\"","title":"DvcTaskError"},{"location":"reference/dvc_task/utils/","text":"General utilities. makedirs ( path , exist_ok = False , mode = None ) Make the specified directory and any parent directories. Source code in dvc_task/utils.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def makedirs ( path : str , exist_ok : bool = False , mode : Optional [ int ] = None ): \"\"\"Make the specified directory and any parent directories.\"\"\" if mode is None : os . makedirs ( path , exist_ok = exist_ok ) return # Modified version of os.makedirs() with support for extended mode # (e.g. S_ISGID) head , tail = os . path . split ( path ) if not tail : head , tail = os . path . split ( head ) if head and tail and not os . path . exists ( head ): try : makedirs ( head , exist_ok = exist_ok , mode = mode ) except FileExistsError : # Defeats race condition when another thread created the path pass cdir = os . curdir if tail == cdir : # foo/newdir/. exists if foo/newdir exists return try : os . mkdir ( path , mode ) except OSError : # Cannot rely on checking for EEXIST, since the operating system # could give priority to other errors like EACCES or EROFS if not exist_ok or not os . path . isdir ( path ): raise try : os . chmod ( path , mode ) except OSError : logger . debug ( \"failed to chmod ' %o ' ' %s '\" , mode , path , exc_info = True ) remove ( path ) Remove the specified path. Source code in dvc_task/utils.py 37 38 39 40 41 42 43 44 45 46 47 def remove ( path : str ): \"\"\"Remove the specified path.\"\"\" logger . debug ( \"Removing ' %s '\" , path ) try : if os . path . isdir ( path ): shutil . rmtree ( path , onerror = _chmod ) else : _unlink ( path , _chmod ) except OSError as exc : if exc . errno != errno . ENOENT : raise unc_path ( path ) Return UNC formatted path. Returns the unmodified path on posix platforms. Source code in dvc_task/utils.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def unc_path ( path : str ) -> str : \"\"\"Return UNC formatted path. Returns the unmodified path on posix platforms. \"\"\" # Celery/Kombu URLs only take absolute filesystem paths # (UNC paths on windows) path = os . path . abspath ( path ) if os . name != \"nt\" : return path drive , tail = os . path . splitdrive ( path ) if drive . endswith ( \":\" ): return f \" \\\\\\\\ ? \\\\ { drive }{ tail } \" return f \" { drive }{ tail } \"","title":"Utils"},{"location":"reference/dvc_task/utils/#dvc_task.utils.makedirs","text":"Make the specified directory and any parent directories. Source code in dvc_task/utils.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def makedirs ( path : str , exist_ok : bool = False , mode : Optional [ int ] = None ): \"\"\"Make the specified directory and any parent directories.\"\"\" if mode is None : os . makedirs ( path , exist_ok = exist_ok ) return # Modified version of os.makedirs() with support for extended mode # (e.g. S_ISGID) head , tail = os . path . split ( path ) if not tail : head , tail = os . path . split ( head ) if head and tail and not os . path . exists ( head ): try : makedirs ( head , exist_ok = exist_ok , mode = mode ) except FileExistsError : # Defeats race condition when another thread created the path pass cdir = os . curdir if tail == cdir : # foo/newdir/. exists if foo/newdir exists return try : os . mkdir ( path , mode ) except OSError : # Cannot rely on checking for EEXIST, since the operating system # could give priority to other errors like EACCES or EROFS if not exist_ok or not os . path . isdir ( path ): raise try : os . chmod ( path , mode ) except OSError : logger . debug ( \"failed to chmod ' %o ' ' %s '\" , mode , path , exc_info = True )","title":"makedirs()"},{"location":"reference/dvc_task/utils/#dvc_task.utils.remove","text":"Remove the specified path. Source code in dvc_task/utils.py 37 38 39 40 41 42 43 44 45 46 47 def remove ( path : str ): \"\"\"Remove the specified path.\"\"\" logger . debug ( \"Removing ' %s '\" , path ) try : if os . path . isdir ( path ): shutil . rmtree ( path , onerror = _chmod ) else : _unlink ( path , _chmod ) except OSError as exc : if exc . errno != errno . ENOENT : raise","title":"remove()"},{"location":"reference/dvc_task/utils/#dvc_task.utils.unc_path","text":"Return UNC formatted path. Returns the unmodified path on posix platforms. Source code in dvc_task/utils.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def unc_path ( path : str ) -> str : \"\"\"Return UNC formatted path. Returns the unmodified path on posix platforms. \"\"\" # Celery/Kombu URLs only take absolute filesystem paths # (UNC paths on windows) path = os . path . abspath ( path ) if os . name != \"nt\" : return path drive , tail = os . path . splitdrive ( path ) if drive . endswith ( \":\" ): return f \" \\\\\\\\ ? \\\\ { drive }{ tail } \" return f \" { drive }{ tail } \"","title":"unc_path()"},{"location":"reference/dvc_task/app/","text":"DVC Task app factories. FSApp Bases: Celery Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend Source code in dvc_task/app/filesystem.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 class FSApp ( Celery ): \"\"\"Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend \"\"\" def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _msg_path_cache : Dict [ str , str ] = {} def __reduce_keys__ ( self ) -> Dict [ str , Any ]: keys = super () . __reduce_keys__ () # type: ignore[misc] keys . update ({ \"wdir\" : self . wdir }) return keys def iter_queued ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : for filename in sorted ( os . listdir ( channel . data_folder_in )): path = os . path . join ( channel . data_folder_in , filename ) try : with open ( path , \"rb\" ) as fobj : payload = fobj . read () except FileNotFoundError : # Messages returned by `listdir` call may have been # acknowledged and moved to `processed_folder` by the # time we try to read them here continue msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) self . _msg_path_cache [ msg . delivery_tag ] = path delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" path = self . _msg_path_cache . get ( delivery_tag ) if path and os . path . exists ( path ): remove ( path ) del self . _msg_path_cache [ delivery_tag ] return for msg in self . iter_queued (): if msg . delivery_tag == delivery_tag : remove ( self . _msg_path_cache [ delivery_tag ]) del self . _msg_path_cache [ delivery_tag ] return raise ValueError ( f \"Message ' { delivery_tag } ' not found\" ) def iter_processed ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : for filename in sorted ( os . listdir ( channel . processed_folder )): with open ( os . path . join ( channel . processed_folder , filename ), \"rb\" ) as fobj : payload = fobj . read () msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg __init__ ( * args , wdir = None , mkdir = False , task_serializer = 'json' , result_serializer = 'json' , ** kwargs ) Construct an FSApp. Parameters: Name Type Description Default wdir Optional [ str ] App broker/results directory. Defaults to current working directory. None mkdir bool Create broker/results subdirectories if they do not already exist. False task_serializer str Default task serializer. 'json' result_serializer str Default result serializer. 'json' Additional arguments will be passed into the Celery constructor. Source code in dvc_task/app/filesystem.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _msg_path_cache : Dict [ str , str ] = {} iter_processed ( queue = None ) Iterate over tasks which have been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in dvc_task/app/filesystem.py 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 def iter_processed ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : for filename in sorted ( os . listdir ( channel . processed_folder )): with open ( os . path . join ( channel . processed_folder , filename ), \"rb\" ) as fobj : payload = fobj . read () msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg iter_queued ( queue = None ) Iterate over queued tasks which have not been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in dvc_task/app/filesystem.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 def iter_queued ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : for filename in sorted ( os . listdir ( channel . data_folder_in )): path = os . path . join ( channel . data_folder_in , filename ) try : with open ( path , \"rb\" ) as fobj : payload = fobj . read () except FileNotFoundError : # Messages returned by `listdir` call may have been # acknowledged and moved to `processed_folder` by the # time we try to read them here continue msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) self . _msg_path_cache [ msg . delivery_tag ] = path delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg reject ( delivery_tag ) Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in dvc_task/app/filesystem.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" path = self . _msg_path_cache . get ( delivery_tag ) if path and os . path . exists ( path ): remove ( path ) del self . _msg_path_cache [ delivery_tag ] return for msg in self . iter_queued (): if msg . delivery_tag == delivery_tag : remove ( self . _msg_path_cache [ delivery_tag ]) del self . _msg_path_cache [ delivery_tag ] return raise ValueError ( f \"Message ' { delivery_tag } ' not found\" )","title":"App"},{"location":"reference/dvc_task/app/#dvc_task.app.FSApp","text":"Bases: Celery Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend Source code in dvc_task/app/filesystem.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 class FSApp ( Celery ): \"\"\"Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend \"\"\" def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _msg_path_cache : Dict [ str , str ] = {} def __reduce_keys__ ( self ) -> Dict [ str , Any ]: keys = super () . __reduce_keys__ () # type: ignore[misc] keys . update ({ \"wdir\" : self . wdir }) return keys def iter_queued ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : for filename in sorted ( os . listdir ( channel . data_folder_in )): path = os . path . join ( channel . data_folder_in , filename ) try : with open ( path , \"rb\" ) as fobj : payload = fobj . read () except FileNotFoundError : # Messages returned by `listdir` call may have been # acknowledged and moved to `processed_folder` by the # time we try to read them here continue msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) self . _msg_path_cache [ msg . delivery_tag ] = path delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" path = self . _msg_path_cache . get ( delivery_tag ) if path and os . path . exists ( path ): remove ( path ) del self . _msg_path_cache [ delivery_tag ] return for msg in self . iter_queued (): if msg . delivery_tag == delivery_tag : remove ( self . _msg_path_cache [ delivery_tag ]) del self . _msg_path_cache [ delivery_tag ] return raise ValueError ( f \"Message ' { delivery_tag } ' not found\" ) def iter_processed ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : for filename in sorted ( os . listdir ( channel . processed_folder )): with open ( os . path . join ( channel . processed_folder , filename ), \"rb\" ) as fobj : payload = fobj . read () msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg","title":"FSApp"},{"location":"reference/dvc_task/app/#dvc_task.app.filesystem.FSApp.__init__","text":"Construct an FSApp. Parameters: Name Type Description Default wdir Optional [ str ] App broker/results directory. Defaults to current working directory. None mkdir bool Create broker/results subdirectories if they do not already exist. False task_serializer str Default task serializer. 'json' result_serializer str Default result serializer. 'json' Additional arguments will be passed into the Celery constructor. Source code in dvc_task/app/filesystem.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _msg_path_cache : Dict [ str , str ] = {}","title":"__init__()"},{"location":"reference/dvc_task/app/#dvc_task.app.filesystem.FSApp.iter_processed","text":"Iterate over tasks which have been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in dvc_task/app/filesystem.py 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 def iter_processed ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : for filename in sorted ( os . listdir ( channel . processed_folder )): with open ( os . path . join ( channel . processed_folder , filename ), \"rb\" ) as fobj : payload = fobj . read () msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg","title":"iter_processed()"},{"location":"reference/dvc_task/app/#dvc_task.app.filesystem.FSApp.iter_queued","text":"Iterate over queued tasks which have not been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in dvc_task/app/filesystem.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 def iter_queued ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : for filename in sorted ( os . listdir ( channel . data_folder_in )): path = os . path . join ( channel . data_folder_in , filename ) try : with open ( path , \"rb\" ) as fobj : payload = fobj . read () except FileNotFoundError : # Messages returned by `listdir` call may have been # acknowledged and moved to `processed_folder` by the # time we try to read them here continue msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) self . _msg_path_cache [ msg . delivery_tag ] = path delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg","title":"iter_queued()"},{"location":"reference/dvc_task/app/#dvc_task.app.filesystem.FSApp.reject","text":"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in dvc_task/app/filesystem.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" path = self . _msg_path_cache . get ( delivery_tag ) if path and os . path . exists ( path ): remove ( path ) del self . _msg_path_cache [ delivery_tag ] return for msg in self . iter_queued (): if msg . delivery_tag == delivery_tag : remove ( self . _msg_path_cache [ delivery_tag ]) del self . _msg_path_cache [ delivery_tag ] return raise ValueError ( f \"Message ' { delivery_tag } ' not found\" )","title":"reject()"},{"location":"reference/dvc_task/app/filesystem/","text":"(Local) filesystem based Celery application. FSApp Bases: Celery Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend Source code in dvc_task/app/filesystem.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 class FSApp ( Celery ): \"\"\"Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend \"\"\" def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _msg_path_cache : Dict [ str , str ] = {} def __reduce_keys__ ( self ) -> Dict [ str , Any ]: keys = super () . __reduce_keys__ () # type: ignore[misc] keys . update ({ \"wdir\" : self . wdir }) return keys def iter_queued ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : for filename in sorted ( os . listdir ( channel . data_folder_in )): path = os . path . join ( channel . data_folder_in , filename ) try : with open ( path , \"rb\" ) as fobj : payload = fobj . read () except FileNotFoundError : # Messages returned by `listdir` call may have been # acknowledged and moved to `processed_folder` by the # time we try to read them here continue msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) self . _msg_path_cache [ msg . delivery_tag ] = path delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" path = self . _msg_path_cache . get ( delivery_tag ) if path and os . path . exists ( path ): remove ( path ) del self . _msg_path_cache [ delivery_tag ] return for msg in self . iter_queued (): if msg . delivery_tag == delivery_tag : remove ( self . _msg_path_cache [ delivery_tag ]) del self . _msg_path_cache [ delivery_tag ] return raise ValueError ( f \"Message ' { delivery_tag } ' not found\" ) def iter_processed ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : for filename in sorted ( os . listdir ( channel . processed_folder )): with open ( os . path . join ( channel . processed_folder , filename ), \"rb\" ) as fobj : payload = fobj . read () msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg __init__ ( * args , wdir = None , mkdir = False , task_serializer = 'json' , result_serializer = 'json' , ** kwargs ) Construct an FSApp. Parameters: Name Type Description Default wdir Optional [ str ] App broker/results directory. Defaults to current working directory. None mkdir bool Create broker/results subdirectories if they do not already exist. False task_serializer str Default task serializer. 'json' result_serializer str Default result serializer. 'json' Additional arguments will be passed into the Celery constructor. Source code in dvc_task/app/filesystem.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _msg_path_cache : Dict [ str , str ] = {} iter_processed ( queue = None ) Iterate over tasks which have been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in dvc_task/app/filesystem.py 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 def iter_processed ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : for filename in sorted ( os . listdir ( channel . processed_folder )): with open ( os . path . join ( channel . processed_folder , filename ), \"rb\" ) as fobj : payload = fobj . read () msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg iter_queued ( queue = None ) Iterate over queued tasks which have not been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in dvc_task/app/filesystem.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 def iter_queued ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : for filename in sorted ( os . listdir ( channel . data_folder_in )): path = os . path . join ( channel . data_folder_in , filename ) try : with open ( path , \"rb\" ) as fobj : payload = fobj . read () except FileNotFoundError : # Messages returned by `listdir` call may have been # acknowledged and moved to `processed_folder` by the # time we try to read them here continue msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) self . _msg_path_cache [ msg . delivery_tag ] = path delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg reject ( delivery_tag ) Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in dvc_task/app/filesystem.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" path = self . _msg_path_cache . get ( delivery_tag ) if path and os . path . exists ( path ): remove ( path ) del self . _msg_path_cache [ delivery_tag ] return for msg in self . iter_queued (): if msg . delivery_tag == delivery_tag : remove ( self . _msg_path_cache [ delivery_tag ]) del self . _msg_path_cache [ delivery_tag ] return raise ValueError ( f \"Message ' { delivery_tag } ' not found\" )","title":"Filesystem"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp","text":"Bases: Celery Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend Source code in dvc_task/app/filesystem.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 class FSApp ( Celery ): \"\"\"Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend \"\"\" def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _msg_path_cache : Dict [ str , str ] = {} def __reduce_keys__ ( self ) -> Dict [ str , Any ]: keys = super () . __reduce_keys__ () # type: ignore[misc] keys . update ({ \"wdir\" : self . wdir }) return keys def iter_queued ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : for filename in sorted ( os . listdir ( channel . data_folder_in )): path = os . path . join ( channel . data_folder_in , filename ) try : with open ( path , \"rb\" ) as fobj : payload = fobj . read () except FileNotFoundError : # Messages returned by `listdir` call may have been # acknowledged and moved to `processed_folder` by the # time we try to read them here continue msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) self . _msg_path_cache [ msg . delivery_tag ] = path delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" path = self . _msg_path_cache . get ( delivery_tag ) if path and os . path . exists ( path ): remove ( path ) del self . _msg_path_cache [ delivery_tag ] return for msg in self . iter_queued (): if msg . delivery_tag == delivery_tag : remove ( self . _msg_path_cache [ delivery_tag ]) del self . _msg_path_cache [ delivery_tag ] return raise ValueError ( f \"Message ' { delivery_tag } ' not found\" ) def iter_processed ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : for filename in sorted ( os . listdir ( channel . processed_folder )): with open ( os . path . join ( channel . processed_folder , filename ), \"rb\" ) as fobj : payload = fobj . read () msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg","title":"FSApp"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp.__init__","text":"Construct an FSApp. Parameters: Name Type Description Default wdir Optional [ str ] App broker/results directory. Defaults to current working directory. None mkdir bool Create broker/results subdirectories if they do not already exist. False task_serializer str Default task serializer. 'json' result_serializer str Default result serializer. 'json' Additional arguments will be passed into the Celery constructor. Source code in dvc_task/app/filesystem.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _msg_path_cache : Dict [ str , str ] = {}","title":"__init__()"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp.iter_processed","text":"Iterate over tasks which have been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in dvc_task/app/filesystem.py 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 def iter_processed ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : for filename in sorted ( os . listdir ( channel . processed_folder )): with open ( os . path . join ( channel . processed_folder , filename ), \"rb\" ) as fobj : payload = fobj . read () msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg","title":"iter_processed()"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp.iter_queued","text":"Iterate over queued tasks which have not been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in dvc_task/app/filesystem.py 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 def iter_queued ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : for filename in sorted ( os . listdir ( channel . data_folder_in )): path = os . path . join ( channel . data_folder_in , filename ) try : with open ( path , \"rb\" ) as fobj : payload = fobj . read () except FileNotFoundError : # Messages returned by `listdir` call may have been # acknowledged and moved to `processed_folder` by the # time we try to read them here continue msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) self . _msg_path_cache [ msg . delivery_tag ] = path delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg","title":"iter_queued()"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp.reject","text":"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in dvc_task/app/filesystem.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" path = self . _msg_path_cache . get ( delivery_tag ) if path and os . path . exists ( path ): remove ( path ) del self . _msg_path_cache [ delivery_tag ] return for msg in self . iter_queued (): if msg . delivery_tag == delivery_tag : remove ( self . _msg_path_cache [ delivery_tag ]) del self . _msg_path_cache [ delivery_tag ] return raise ValueError ( f \"Message ' { delivery_tag } ' not found\" )","title":"reject()"},{"location":"reference/dvc_task/proc/","text":"Process management module. ManagedProcess Bases: AbstractContextManager Class to manage the specified process with redirected output. stdout and stderr will both be redirected to .out. Interactive processes (requiring stdin input) are currently unsupported. Source code in dvc_task/proc/process.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 class ManagedProcess ( AbstractContextManager ): \"\"\"Class to manage the specified process with redirected output. stdout and stderr will both be redirected to <name>.out. Interactive processes (requiring stdin input) are currently unsupported. \"\"\" def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None def __enter__ ( self ): if self . _proc is None : self . run () return self def __exit__ ( self , * args , ** kwargs ): self . wait () def _close_fds ( self ): with self . _fd_stack : pass def _make_path ( self , path : str ) -> str : return os . path . join ( self . wdir , path ) if self . wdir else path @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) @property def info ( self ) -> \"ProcessInfo\" : \"\"\"Return process information.\"\"\" return ProcessInfo ( pid = self . pid , stdin = None , stdout = self . stdout_path , stderr = None , returncode = self . returncode , ) @property def pid ( self ) -> int : \"\"\"Return process PID. Raises: ValueError: Process is not running. \"\"\" if self . _proc is None : raise ValueError return self . _proc . pid def _make_wdir ( self ): if self . wdir : makedirs ( self . wdir , exist_ok = True ) def _dump ( self ): self . _make_wdir () self . info . dump ( self . info_path ) with open ( self . pidfile_path , \"w\" , encoding = \"utf-8\" ) as fobj : fobj . write ( str ( self . pid )) def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid @classmethod def _spawn ( cls , * args , ** kwargs ): with cls ( * args , ** kwargs ): pass __init__ ( args , env = None , wdir = None , name = None ) Construct a MangedProcess. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to be run. required env Optional [ Dict [ str , str ]] Optional environment variables. None wdir Optional [ str ] If specified, redirected output files will be placed in wdir . Defaults to current working directory. None name Optional [ str ] Name to use for this process, if not specified a UUID will be generated instead. None Source code in dvc_task/proc/process.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None info () property Return process information. Source code in dvc_task/proc/process.py 120 121 122 123 124 125 126 127 128 129 @property def info ( self ) -> \"ProcessInfo\" : \"\"\"Return process information.\"\"\" return ProcessInfo ( pid = self . pid , stdin = None , stdout = self . stdout_path , stderr = None , returncode = self . returncode , ) info_path () Return process information file path. Source code in dvc_task/proc/process.py 110 111 112 113 @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) pid () property Return process PID. Raises: Type Description ValueError Process is not running. Source code in dvc_task/proc/process.py 131 132 133 134 135 136 137 138 139 140 @property def pid ( self ) -> int : \"\"\"Return process PID. Raises: ValueError: Process is not running. \"\"\" if self . _proc is None : raise ValueError return self . _proc . pid pidfile_path () Return process pidfile path. Source code in dvc_task/proc/process.py 115 116 117 118 @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) run () Run this process. Source code in dvc_task/proc/process.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise spawn ( * args , ** kwargs ) classmethod Spawn a ManagedProcess command in the background. Source code in dvc_task/proc/process.py 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid stdout_path () Return redirected stdout path. Source code in dvc_task/proc/process.py 105 106 107 108 @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) wait ( timeout = None ) Block until a process started with run has completed. Source code in dvc_task/proc/process.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode ProcessInfo dataclass Process information. Source code in dvc_task/proc/process.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 @dataclass class ProcessInfo : \"\"\"Process information.\"\"\" pid : int stdin : Optional [ str ] stdout : Optional [ str ] stderr : Optional [ str ] returncode : Optional [ int ] @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , \"r\" , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj )) def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" temp_info_file = f \" { filename } . { uuid () } \" with open ( temp_info_file , \"w\" , encoding = \"utf-8\" ) as fobj : json . dump ( self . asdict (), fobj ) os . replace ( temp_info_file , filename ) asdict () Return this info as a dictionary. Source code in dvc_task/proc/process.py 42 43 44 def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) dump ( filename ) Dump the process information into a file. Source code in dvc_task/proc/process.py 46 47 48 49 50 51 def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" temp_info_file = f \" { filename } . { uuid () } \" with open ( temp_info_file , \"w\" , encoding = \"utf-8\" ) as fobj : json . dump ( self . asdict (), fobj ) os . replace ( temp_info_file , filename ) from_dict ( data ) classmethod Construct ProcessInfo from the specified dictionary. Source code in dvc_task/proc/process.py 31 32 33 34 @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) load ( filename ) classmethod Construct the process information from a file. Source code in dvc_task/proc/process.py 36 37 38 39 40 @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , \"r\" , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj )) ProcessManager Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. Source code in dvc_task/proc/manager.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 class ProcessManager : \"\"\"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. \"\"\" def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir def __iter__ ( self ) -> Generator [ str , None , None ]: if not os . path . exists ( self . wdir ): return for name in os . listdir ( self . wdir ): yield name def __getitem__ ( self , key : str ) -> \"ProcessInfo\" : info_path = self . _get_info_path ( key ) try : return ProcessInfo . load ( info_path ) except FileNotFoundError as exc : raise KeyError from exc @reraise ( FileNotFoundError , KeyError ) def __setitem__ ( self , key : str , value : \"ProcessInfo\" ): info_path = self . _get_info_path ( key ) value . dump ( info_path ) def __delitem__ ( self , key : str ) -> None : path = os . path . join ( self . wdir , key ) if os . path . exists ( path ): remove ( path ) def _get_info_path ( self , key : str ) -> str : return os . path . join ( self . wdir , key , f \" { key } .json\" ) def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) def send_signal ( self , name : str , sig : int ): \"\"\"Send `signal` to the specified named process.\"\"\" process_info = self [ name ] if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise def terminate ( self , name : str ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM ) def kill ( self , name : str ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM ) else : self . send_signal ( name , signal . SIGKILL ) # pylint: disable=no-member def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset ) __init__ ( wdir = None ) Construct a ProcessManager Parameters: Name Type Description Default wdir Optional [ str ] Directory used for storing process information. Defaults to the current working directory. None Source code in dvc_task/proc/manager.py 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir cleanup ( force = False ) Remove stale (terminated) processes from this manager. Source code in dvc_task/proc/manager.py 181 182 183 184 185 186 187 def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue follow ( name , encoding = None , sleep_interval = 1 ) Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Parameters: Name Type Description Default name str Process name. required encoding Optional [ str ] Text encoding for redirected output. Defaults to locale.getpreferredencoding() . None sleep_interval int Sleep interval for follow iterations (when waiting for output). 1 Note Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). Source code in dvc_task/proc/manager.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset ) get ( key , default = None ) Return the specified process. Source code in dvc_task/proc/manager.py 68 69 70 71 72 73 def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default kill ( name ) Kill the specified named process. Source code in dvc_task/proc/manager.py 152 153 154 155 156 157 def kill ( self , name : str ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM ) else : self . send_signal ( name , signal . SIGKILL ) # pylint: disable=no-member processes () Iterate over managed processes. Source code in dvc_task/proc/manager.py 75 76 77 78 79 80 81 def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue remove ( name , force = False ) Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if force is True`, otherwise an exception will be raised. Source code in dvc_task/proc/manager.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] run_signature ( args , name = None , task = None , env = None , immutable = False ) Return signature for a task which runs a command in the background. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to run. required name Optional [ str ] Optional name to use for the spawned process. None task Optional [ str ] Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. None env Optional [ Dict [ str , str ]] Optional environment to be passed into the process. None immutable bool True if the returned Signature should be immutable. False Returns: Type Description Signature Celery signature for the run task. Source code in dvc_task/proc/manager.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) send_signal ( name , sig ) Send signal to the specified named process. Source code in dvc_task/proc/manager.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def send_signal ( self , name : str , sig : int ): \"\"\"Send `signal` to the specified named process.\"\"\" process_info = self [ name ] if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise terminate ( name ) Terminate the specified named process. Source code in dvc_task/proc/manager.py 148 149 150 def terminate ( self , name : str ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM )","title":"Proc"},{"location":"reference/dvc_task/proc/#dvc_task.proc.ManagedProcess","text":"Bases: AbstractContextManager Class to manage the specified process with redirected output. stdout and stderr will both be redirected to .out. Interactive processes (requiring stdin input) are currently unsupported. Source code in dvc_task/proc/process.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 class ManagedProcess ( AbstractContextManager ): \"\"\"Class to manage the specified process with redirected output. stdout and stderr will both be redirected to <name>.out. Interactive processes (requiring stdin input) are currently unsupported. \"\"\" def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None def __enter__ ( self ): if self . _proc is None : self . run () return self def __exit__ ( self , * args , ** kwargs ): self . wait () def _close_fds ( self ): with self . _fd_stack : pass def _make_path ( self , path : str ) -> str : return os . path . join ( self . wdir , path ) if self . wdir else path @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) @property def info ( self ) -> \"ProcessInfo\" : \"\"\"Return process information.\"\"\" return ProcessInfo ( pid = self . pid , stdin = None , stdout = self . stdout_path , stderr = None , returncode = self . returncode , ) @property def pid ( self ) -> int : \"\"\"Return process PID. Raises: ValueError: Process is not running. \"\"\" if self . _proc is None : raise ValueError return self . _proc . pid def _make_wdir ( self ): if self . wdir : makedirs ( self . wdir , exist_ok = True ) def _dump ( self ): self . _make_wdir () self . info . dump ( self . info_path ) with open ( self . pidfile_path , \"w\" , encoding = \"utf-8\" ) as fobj : fobj . write ( str ( self . pid )) def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid @classmethod def _spawn ( cls , * args , ** kwargs ): with cls ( * args , ** kwargs ): pass","title":"ManagedProcess"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.__init__","text":"Construct a MangedProcess. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to be run. required env Optional [ Dict [ str , str ]] Optional environment variables. None wdir Optional [ str ] If specified, redirected output files will be placed in wdir . Defaults to current working directory. None name Optional [ str ] Name to use for this process, if not specified a UUID will be generated instead. None Source code in dvc_task/proc/process.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None","title":"__init__()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.info","text":"Return process information. Source code in dvc_task/proc/process.py 120 121 122 123 124 125 126 127 128 129 @property def info ( self ) -> \"ProcessInfo\" : \"\"\"Return process information.\"\"\" return ProcessInfo ( pid = self . pid , stdin = None , stdout = self . stdout_path , stderr = None , returncode = self . returncode , )","title":"info()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.info_path","text":"Return process information file path. Source code in dvc_task/proc/process.py 110 111 112 113 @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" )","title":"info_path()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.pid","text":"Return process PID. Raises: Type Description ValueError Process is not running. Source code in dvc_task/proc/process.py 131 132 133 134 135 136 137 138 139 140 @property def pid ( self ) -> int : \"\"\"Return process PID. Raises: ValueError: Process is not running. \"\"\" if self . _proc is None : raise ValueError return self . _proc . pid","title":"pid()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.pidfile_path","text":"Return process pidfile path. Source code in dvc_task/proc/process.py 115 116 117 118 @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" )","title":"pidfile_path()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.run","text":"Run this process. Source code in dvc_task/proc/process.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise","title":"run()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.spawn","text":"Spawn a ManagedProcess command in the background. Source code in dvc_task/proc/process.py 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid","title":"spawn()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.stdout_path","text":"Return redirected stdout path. Source code in dvc_task/proc/process.py 105 106 107 108 @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" )","title":"stdout_path()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.wait","text":"Block until a process started with run has completed. Source code in dvc_task/proc/process.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode","title":"wait()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.ProcessInfo","text":"Process information. Source code in dvc_task/proc/process.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 @dataclass class ProcessInfo : \"\"\"Process information.\"\"\" pid : int stdin : Optional [ str ] stdout : Optional [ str ] stderr : Optional [ str ] returncode : Optional [ int ] @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , \"r\" , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj )) def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" temp_info_file = f \" { filename } . { uuid () } \" with open ( temp_info_file , \"w\" , encoding = \"utf-8\" ) as fobj : json . dump ( self . asdict (), fobj ) os . replace ( temp_info_file , filename )","title":"ProcessInfo"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ProcessInfo.asdict","text":"Return this info as a dictionary. Source code in dvc_task/proc/process.py 42 43 44 def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self )","title":"asdict()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ProcessInfo.dump","text":"Dump the process information into a file. Source code in dvc_task/proc/process.py 46 47 48 49 50 51 def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" temp_info_file = f \" { filename } . { uuid () } \" with open ( temp_info_file , \"w\" , encoding = \"utf-8\" ) as fobj : json . dump ( self . asdict (), fobj ) os . replace ( temp_info_file , filename )","title":"dump()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ProcessInfo.from_dict","text":"Construct ProcessInfo from the specified dictionary. Source code in dvc_task/proc/process.py 31 32 33 34 @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data )","title":"from_dict()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ProcessInfo.load","text":"Construct the process information from a file. Source code in dvc_task/proc/process.py 36 37 38 39 40 @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , \"r\" , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj ))","title":"load()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.ProcessManager","text":"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. Source code in dvc_task/proc/manager.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 class ProcessManager : \"\"\"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. \"\"\" def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir def __iter__ ( self ) -> Generator [ str , None , None ]: if not os . path . exists ( self . wdir ): return for name in os . listdir ( self . wdir ): yield name def __getitem__ ( self , key : str ) -> \"ProcessInfo\" : info_path = self . _get_info_path ( key ) try : return ProcessInfo . load ( info_path ) except FileNotFoundError as exc : raise KeyError from exc @reraise ( FileNotFoundError , KeyError ) def __setitem__ ( self , key : str , value : \"ProcessInfo\" ): info_path = self . _get_info_path ( key ) value . dump ( info_path ) def __delitem__ ( self , key : str ) -> None : path = os . path . join ( self . wdir , key ) if os . path . exists ( path ): remove ( path ) def _get_info_path ( self , key : str ) -> str : return os . path . join ( self . wdir , key , f \" { key } .json\" ) def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) def send_signal ( self , name : str , sig : int ): \"\"\"Send `signal` to the specified named process.\"\"\" process_info = self [ name ] if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise def terminate ( self , name : str ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM ) def kill ( self , name : str ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM ) else : self . send_signal ( name , signal . SIGKILL ) # pylint: disable=no-member def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset )","title":"ProcessManager"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.__init__","text":"Construct a ProcessManager Parameters: Name Type Description Default wdir Optional [ str ] Directory used for storing process information. Defaults to the current working directory. None Source code in dvc_task/proc/manager.py 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir","title":"__init__()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.cleanup","text":"Remove stale (terminated) processes from this manager. Source code in dvc_task/proc/manager.py 181 182 183 184 185 186 187 def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue","title":"cleanup()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.follow","text":"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Parameters: Name Type Description Default name str Process name. required encoding Optional [ str ] Text encoding for redirected output. Defaults to locale.getpreferredencoding() . None sleep_interval int Sleep interval for follow iterations (when waiting for output). 1 Note Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). Source code in dvc_task/proc/manager.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset )","title":"follow()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.get","text":"Return the specified process. Source code in dvc_task/proc/manager.py 68 69 70 71 72 73 def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default","title":"get()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.kill","text":"Kill the specified named process. Source code in dvc_task/proc/manager.py 152 153 154 155 156 157 def kill ( self , name : str ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM ) else : self . send_signal ( name , signal . SIGKILL ) # pylint: disable=no-member","title":"kill()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.processes","text":"Iterate over managed processes. Source code in dvc_task/proc/manager.py 75 76 77 78 79 80 81 def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue","title":"processes()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.remove","text":"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if force is True`, otherwise an exception will be raised. Source code in dvc_task/proc/manager.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ]","title":"remove()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.run_signature","text":"Return signature for a task which runs a command in the background. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to run. required name Optional [ str ] Optional name to use for the spawned process. None task Optional [ str ] Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. None env Optional [ Dict [ str , str ]] Optional environment to be passed into the process. None immutable bool True if the returned Signature should be immutable. False Returns: Type Description Signature Celery signature for the run task. Source code in dvc_task/proc/manager.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , )","title":"run_signature()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.send_signal","text":"Send signal to the specified named process. Source code in dvc_task/proc/manager.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def send_signal ( self , name : str , sig : int ): \"\"\"Send `signal` to the specified named process.\"\"\" process_info = self [ name ] if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise","title":"send_signal()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.terminate","text":"Terminate the specified named process. Source code in dvc_task/proc/manager.py 148 149 150 def terminate ( self , name : str ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM )","title":"terminate()"},{"location":"reference/dvc_task/proc/exceptions/","text":"Process exceptions. ProcessNotFoundError Bases: DvcTaskError Process does not exist. Source code in dvc_task/proc/exceptions.py 12 13 14 15 16 class ProcessNotFoundError ( DvcTaskError ): \"\"\"Process does not exist.\"\"\" def __init__ ( self , name ): super () . __init__ ( f \"Managed process ' { name } ' does not exist.\" ) ProcessNotTerminatedError Bases: DvcTaskError Process is still running. Source code in dvc_task/proc/exceptions.py 5 6 7 8 9 class ProcessNotTerminatedError ( DvcTaskError ): \"\"\"Process is still running.\"\"\" def __init__ ( self , name ): super () . __init__ ( f \"Managed process ' { name } ' has not been terminated.\" ) TimeoutExpired Bases: DvcTaskError Process timeout expired. Source code in dvc_task/proc/exceptions.py 19 20 21 22 23 24 25 26 27 class TimeoutExpired ( DvcTaskError ): \"\"\"Process timeout expired.\"\"\" def __init__ ( self , cmd , timeout ): super () . __init__ ( f \"' { cmd } ' did not complete before timeout ' { timeout } '\" ) self . cmd = cmd self . timeout = timeout UnsupportedSignalError Bases: DvcTaskError Unsupported process signal. Source code in dvc_task/proc/exceptions.py 30 31 32 33 34 class UnsupportedSignalError ( DvcTaskError ): \"\"\"Unsupported process signal.\"\"\" def __init__ ( self , sig ): super () . __init__ ( f \"Unsupported signal: { sig } \" )","title":"Exceptions"},{"location":"reference/dvc_task/proc/exceptions/#dvc_task.proc.exceptions.ProcessNotFoundError","text":"Bases: DvcTaskError Process does not exist. Source code in dvc_task/proc/exceptions.py 12 13 14 15 16 class ProcessNotFoundError ( DvcTaskError ): \"\"\"Process does not exist.\"\"\" def __init__ ( self , name ): super () . __init__ ( f \"Managed process ' { name } ' does not exist.\" )","title":"ProcessNotFoundError"},{"location":"reference/dvc_task/proc/exceptions/#dvc_task.proc.exceptions.ProcessNotTerminatedError","text":"Bases: DvcTaskError Process is still running. Source code in dvc_task/proc/exceptions.py 5 6 7 8 9 class ProcessNotTerminatedError ( DvcTaskError ): \"\"\"Process is still running.\"\"\" def __init__ ( self , name ): super () . __init__ ( f \"Managed process ' { name } ' has not been terminated.\" )","title":"ProcessNotTerminatedError"},{"location":"reference/dvc_task/proc/exceptions/#dvc_task.proc.exceptions.TimeoutExpired","text":"Bases: DvcTaskError Process timeout expired. Source code in dvc_task/proc/exceptions.py 19 20 21 22 23 24 25 26 27 class TimeoutExpired ( DvcTaskError ): \"\"\"Process timeout expired.\"\"\" def __init__ ( self , cmd , timeout ): super () . __init__ ( f \"' { cmd } ' did not complete before timeout ' { timeout } '\" ) self . cmd = cmd self . timeout = timeout","title":"TimeoutExpired"},{"location":"reference/dvc_task/proc/exceptions/#dvc_task.proc.exceptions.UnsupportedSignalError","text":"Bases: DvcTaskError Unsupported process signal. Source code in dvc_task/proc/exceptions.py 30 31 32 33 34 class UnsupportedSignalError ( DvcTaskError ): \"\"\"Unsupported process signal.\"\"\" def __init__ ( self , sig ): super () . __init__ ( f \"Unsupported signal: { sig } \" )","title":"UnsupportedSignalError"},{"location":"reference/dvc_task/proc/manager/","text":"Serverless process manager. ProcessManager Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. Source code in dvc_task/proc/manager.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 class ProcessManager : \"\"\"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. \"\"\" def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir def __iter__ ( self ) -> Generator [ str , None , None ]: if not os . path . exists ( self . wdir ): return for name in os . listdir ( self . wdir ): yield name def __getitem__ ( self , key : str ) -> \"ProcessInfo\" : info_path = self . _get_info_path ( key ) try : return ProcessInfo . load ( info_path ) except FileNotFoundError as exc : raise KeyError from exc @reraise ( FileNotFoundError , KeyError ) def __setitem__ ( self , key : str , value : \"ProcessInfo\" ): info_path = self . _get_info_path ( key ) value . dump ( info_path ) def __delitem__ ( self , key : str ) -> None : path = os . path . join ( self . wdir , key ) if os . path . exists ( path ): remove ( path ) def _get_info_path ( self , key : str ) -> str : return os . path . join ( self . wdir , key , f \" { key } .json\" ) def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) def send_signal ( self , name : str , sig : int ): \"\"\"Send `signal` to the specified named process.\"\"\" process_info = self [ name ] if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise def terminate ( self , name : str ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM ) def kill ( self , name : str ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM ) else : self . send_signal ( name , signal . SIGKILL ) # pylint: disable=no-member def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset ) __init__ ( wdir = None ) Construct a ProcessManager Parameters: Name Type Description Default wdir Optional [ str ] Directory used for storing process information. Defaults to the current working directory. None Source code in dvc_task/proc/manager.py 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir cleanup ( force = False ) Remove stale (terminated) processes from this manager. Source code in dvc_task/proc/manager.py 181 182 183 184 185 186 187 def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue follow ( name , encoding = None , sleep_interval = 1 ) Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Parameters: Name Type Description Default name str Process name. required encoding Optional [ str ] Text encoding for redirected output. Defaults to locale.getpreferredencoding() . None sleep_interval int Sleep interval for follow iterations (when waiting for output). 1 Note Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). Source code in dvc_task/proc/manager.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset ) get ( key , default = None ) Return the specified process. Source code in dvc_task/proc/manager.py 68 69 70 71 72 73 def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default kill ( name ) Kill the specified named process. Source code in dvc_task/proc/manager.py 152 153 154 155 156 157 def kill ( self , name : str ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM ) else : self . send_signal ( name , signal . SIGKILL ) # pylint: disable=no-member processes () Iterate over managed processes. Source code in dvc_task/proc/manager.py 75 76 77 78 79 80 81 def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue remove ( name , force = False ) Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if force is True`, otherwise an exception will be raised. Source code in dvc_task/proc/manager.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] run_signature ( args , name = None , task = None , env = None , immutable = False ) Return signature for a task which runs a command in the background. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to run. required name Optional [ str ] Optional name to use for the spawned process. None task Optional [ str ] Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. None env Optional [ Dict [ str , str ]] Optional environment to be passed into the process. None immutable bool True if the returned Signature should be immutable. False Returns: Type Description Signature Celery signature for the run task. Source code in dvc_task/proc/manager.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) send_signal ( name , sig ) Send signal to the specified named process. Source code in dvc_task/proc/manager.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def send_signal ( self , name : str , sig : int ): \"\"\"Send `signal` to the specified named process.\"\"\" process_info = self [ name ] if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise terminate ( name ) Terminate the specified named process. Source code in dvc_task/proc/manager.py 148 149 150 def terminate ( self , name : str ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM )","title":"Manager"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager","text":"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. Source code in dvc_task/proc/manager.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 class ProcessManager : \"\"\"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. \"\"\" def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir def __iter__ ( self ) -> Generator [ str , None , None ]: if not os . path . exists ( self . wdir ): return for name in os . listdir ( self . wdir ): yield name def __getitem__ ( self , key : str ) -> \"ProcessInfo\" : info_path = self . _get_info_path ( key ) try : return ProcessInfo . load ( info_path ) except FileNotFoundError as exc : raise KeyError from exc @reraise ( FileNotFoundError , KeyError ) def __setitem__ ( self , key : str , value : \"ProcessInfo\" ): info_path = self . _get_info_path ( key ) value . dump ( info_path ) def __delitem__ ( self , key : str ) -> None : path = os . path . join ( self . wdir , key ) if os . path . exists ( path ): remove ( path ) def _get_info_path ( self , key : str ) -> str : return os . path . join ( self . wdir , key , f \" { key } .json\" ) def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) def send_signal ( self , name : str , sig : int ): \"\"\"Send `signal` to the specified named process.\"\"\" process_info = self [ name ] if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise def terminate ( self , name : str ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM ) def kill ( self , name : str ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM ) else : self . send_signal ( name , signal . SIGKILL ) # pylint: disable=no-member def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset )","title":"ProcessManager"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.__init__","text":"Construct a ProcessManager Parameters: Name Type Description Default wdir Optional [ str ] Directory used for storing process information. Defaults to the current working directory. None Source code in dvc_task/proc/manager.py 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir","title":"__init__()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.cleanup","text":"Remove stale (terminated) processes from this manager. Source code in dvc_task/proc/manager.py 181 182 183 184 185 186 187 def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue","title":"cleanup()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.follow","text":"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Parameters: Name Type Description Default name str Process name. required encoding Optional [ str ] Text encoding for redirected output. Defaults to locale.getpreferredencoding() . None sleep_interval int Sleep interval for follow iterations (when waiting for output). 1 Note Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). Source code in dvc_task/proc/manager.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset )","title":"follow()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.get","text":"Return the specified process. Source code in dvc_task/proc/manager.py 68 69 70 71 72 73 def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default","title":"get()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.kill","text":"Kill the specified named process. Source code in dvc_task/proc/manager.py 152 153 154 155 156 157 def kill ( self , name : str ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM ) else : self . send_signal ( name , signal . SIGKILL ) # pylint: disable=no-member","title":"kill()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.processes","text":"Iterate over managed processes. Source code in dvc_task/proc/manager.py 75 76 77 78 79 80 81 def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue","title":"processes()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.remove","text":"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if force is True`, otherwise an exception will be raised. Source code in dvc_task/proc/manager.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ]","title":"remove()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.run_signature","text":"Return signature for a task which runs a command in the background. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to run. required name Optional [ str ] Optional name to use for the spawned process. None task Optional [ str ] Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. None env Optional [ Dict [ str , str ]] Optional environment to be passed into the process. None immutable bool True if the returned Signature should be immutable. False Returns: Type Description Signature Celery signature for the run task. Source code in dvc_task/proc/manager.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , )","title":"run_signature()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.send_signal","text":"Send signal to the specified named process. Source code in dvc_task/proc/manager.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def send_signal ( self , name : str , sig : int ): \"\"\"Send `signal` to the specified named process.\"\"\" process_info = self [ name ] if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise","title":"send_signal()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.terminate","text":"Terminate the specified named process. Source code in dvc_task/proc/manager.py 148 149 150 def terminate ( self , name : str ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM )","title":"terminate()"},{"location":"reference/dvc_task/proc/process/","text":"Managed process module. ManagedProcess Bases: AbstractContextManager Class to manage the specified process with redirected output. stdout and stderr will both be redirected to .out. Interactive processes (requiring stdin input) are currently unsupported. Source code in dvc_task/proc/process.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 class ManagedProcess ( AbstractContextManager ): \"\"\"Class to manage the specified process with redirected output. stdout and stderr will both be redirected to <name>.out. Interactive processes (requiring stdin input) are currently unsupported. \"\"\" def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None def __enter__ ( self ): if self . _proc is None : self . run () return self def __exit__ ( self , * args , ** kwargs ): self . wait () def _close_fds ( self ): with self . _fd_stack : pass def _make_path ( self , path : str ) -> str : return os . path . join ( self . wdir , path ) if self . wdir else path @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) @property def info ( self ) -> \"ProcessInfo\" : \"\"\"Return process information.\"\"\" return ProcessInfo ( pid = self . pid , stdin = None , stdout = self . stdout_path , stderr = None , returncode = self . returncode , ) @property def pid ( self ) -> int : \"\"\"Return process PID. Raises: ValueError: Process is not running. \"\"\" if self . _proc is None : raise ValueError return self . _proc . pid def _make_wdir ( self ): if self . wdir : makedirs ( self . wdir , exist_ok = True ) def _dump ( self ): self . _make_wdir () self . info . dump ( self . info_path ) with open ( self . pidfile_path , \"w\" , encoding = \"utf-8\" ) as fobj : fobj . write ( str ( self . pid )) def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid @classmethod def _spawn ( cls , * args , ** kwargs ): with cls ( * args , ** kwargs ): pass __init__ ( args , env = None , wdir = None , name = None ) Construct a MangedProcess. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to be run. required env Optional [ Dict [ str , str ]] Optional environment variables. None wdir Optional [ str ] If specified, redirected output files will be placed in wdir . Defaults to current working directory. None name Optional [ str ] Name to use for this process, if not specified a UUID will be generated instead. None Source code in dvc_task/proc/process.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None info () property Return process information. Source code in dvc_task/proc/process.py 120 121 122 123 124 125 126 127 128 129 @property def info ( self ) -> \"ProcessInfo\" : \"\"\"Return process information.\"\"\" return ProcessInfo ( pid = self . pid , stdin = None , stdout = self . stdout_path , stderr = None , returncode = self . returncode , ) info_path () Return process information file path. Source code in dvc_task/proc/process.py 110 111 112 113 @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) pid () property Return process PID. Raises: Type Description ValueError Process is not running. Source code in dvc_task/proc/process.py 131 132 133 134 135 136 137 138 139 140 @property def pid ( self ) -> int : \"\"\"Return process PID. Raises: ValueError: Process is not running. \"\"\" if self . _proc is None : raise ValueError return self . _proc . pid pidfile_path () Return process pidfile path. Source code in dvc_task/proc/process.py 115 116 117 118 @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) run () Run this process. Source code in dvc_task/proc/process.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise spawn ( * args , ** kwargs ) classmethod Spawn a ManagedProcess command in the background. Source code in dvc_task/proc/process.py 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid stdout_path () Return redirected stdout path. Source code in dvc_task/proc/process.py 105 106 107 108 @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) wait ( timeout = None ) Block until a process started with run has completed. Source code in dvc_task/proc/process.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode ProcessInfo dataclass Process information. Source code in dvc_task/proc/process.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 @dataclass class ProcessInfo : \"\"\"Process information.\"\"\" pid : int stdin : Optional [ str ] stdout : Optional [ str ] stderr : Optional [ str ] returncode : Optional [ int ] @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , \"r\" , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj )) def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" temp_info_file = f \" { filename } . { uuid () } \" with open ( temp_info_file , \"w\" , encoding = \"utf-8\" ) as fobj : json . dump ( self . asdict (), fobj ) os . replace ( temp_info_file , filename ) asdict () Return this info as a dictionary. Source code in dvc_task/proc/process.py 42 43 44 def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) dump ( filename ) Dump the process information into a file. Source code in dvc_task/proc/process.py 46 47 48 49 50 51 def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" temp_info_file = f \" { filename } . { uuid () } \" with open ( temp_info_file , \"w\" , encoding = \"utf-8\" ) as fobj : json . dump ( self . asdict (), fobj ) os . replace ( temp_info_file , filename ) from_dict ( data ) classmethod Construct ProcessInfo from the specified dictionary. Source code in dvc_task/proc/process.py 31 32 33 34 @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) load ( filename ) classmethod Construct the process information from a file. Source code in dvc_task/proc/process.py 36 37 38 39 40 @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , \"r\" , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj ))","title":"Process"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess","text":"Bases: AbstractContextManager Class to manage the specified process with redirected output. stdout and stderr will both be redirected to .out. Interactive processes (requiring stdin input) are currently unsupported. Source code in dvc_task/proc/process.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 class ManagedProcess ( AbstractContextManager ): \"\"\"Class to manage the specified process with redirected output. stdout and stderr will both be redirected to <name>.out. Interactive processes (requiring stdin input) are currently unsupported. \"\"\" def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None def __enter__ ( self ): if self . _proc is None : self . run () return self def __exit__ ( self , * args , ** kwargs ): self . wait () def _close_fds ( self ): with self . _fd_stack : pass def _make_path ( self , path : str ) -> str : return os . path . join ( self . wdir , path ) if self . wdir else path @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) @property def info ( self ) -> \"ProcessInfo\" : \"\"\"Return process information.\"\"\" return ProcessInfo ( pid = self . pid , stdin = None , stdout = self . stdout_path , stderr = None , returncode = self . returncode , ) @property def pid ( self ) -> int : \"\"\"Return process PID. Raises: ValueError: Process is not running. \"\"\" if self . _proc is None : raise ValueError return self . _proc . pid def _make_wdir ( self ): if self . wdir : makedirs ( self . wdir , exist_ok = True ) def _dump ( self ): self . _make_wdir () self . info . dump ( self . info_path ) with open ( self . pidfile_path , \"w\" , encoding = \"utf-8\" ) as fobj : fobj . write ( str ( self . pid )) def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid @classmethod def _spawn ( cls , * args , ** kwargs ): with cls ( * args , ** kwargs ): pass","title":"ManagedProcess"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.__init__","text":"Construct a MangedProcess. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to be run. required env Optional [ Dict [ str , str ]] Optional environment variables. None wdir Optional [ str ] If specified, redirected output files will be placed in wdir . Defaults to current working directory. None name Optional [ str ] Name to use for this process, if not specified a UUID will be generated instead. None Source code in dvc_task/proc/process.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None","title":"__init__()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.info","text":"Return process information. Source code in dvc_task/proc/process.py 120 121 122 123 124 125 126 127 128 129 @property def info ( self ) -> \"ProcessInfo\" : \"\"\"Return process information.\"\"\" return ProcessInfo ( pid = self . pid , stdin = None , stdout = self . stdout_path , stderr = None , returncode = self . returncode , )","title":"info()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.info_path","text":"Return process information file path. Source code in dvc_task/proc/process.py 110 111 112 113 @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" )","title":"info_path()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.pid","text":"Return process PID. Raises: Type Description ValueError Process is not running. Source code in dvc_task/proc/process.py 131 132 133 134 135 136 137 138 139 140 @property def pid ( self ) -> int : \"\"\"Return process PID. Raises: ValueError: Process is not running. \"\"\" if self . _proc is None : raise ValueError return self . _proc . pid","title":"pid()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.pidfile_path","text":"Return process pidfile path. Source code in dvc_task/proc/process.py 115 116 117 118 @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" )","title":"pidfile_path()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.run","text":"Run this process. Source code in dvc_task/proc/process.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise","title":"run()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.spawn","text":"Spawn a ManagedProcess command in the background. Source code in dvc_task/proc/process.py 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid","title":"spawn()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.stdout_path","text":"Return redirected stdout path. Source code in dvc_task/proc/process.py 105 106 107 108 @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" )","title":"stdout_path()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.wait","text":"Block until a process started with run has completed. Source code in dvc_task/proc/process.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode","title":"wait()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ProcessInfo","text":"Process information. Source code in dvc_task/proc/process.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 @dataclass class ProcessInfo : \"\"\"Process information.\"\"\" pid : int stdin : Optional [ str ] stdout : Optional [ str ] stderr : Optional [ str ] returncode : Optional [ int ] @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , \"r\" , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj )) def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" temp_info_file = f \" { filename } . { uuid () } \" with open ( temp_info_file , \"w\" , encoding = \"utf-8\" ) as fobj : json . dump ( self . asdict (), fobj ) os . replace ( temp_info_file , filename )","title":"ProcessInfo"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ProcessInfo.asdict","text":"Return this info as a dictionary. Source code in dvc_task/proc/process.py 42 43 44 def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self )","title":"asdict()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ProcessInfo.dump","text":"Dump the process information into a file. Source code in dvc_task/proc/process.py 46 47 48 49 50 51 def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" temp_info_file = f \" { filename } . { uuid () } \" with open ( temp_info_file , \"w\" , encoding = \"utf-8\" ) as fobj : json . dump ( self . asdict (), fobj ) os . replace ( temp_info_file , filename )","title":"dump()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ProcessInfo.from_dict","text":"Construct ProcessInfo from the specified dictionary. Source code in dvc_task/proc/process.py 31 32 33 34 @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data )","title":"from_dict()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ProcessInfo.load","text":"Construct the process information from a file. Source code in dvc_task/proc/process.py 36 37 38 39 40 @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , \"r\" , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj ))","title":"load()"},{"location":"reference/dvc_task/proc/tasks/","text":"Celery tasks. run ( self , * args , ** kwargs ) Run a command inside a celery task. Accepts the same arguments as proc.process.ManagedProcess . Source code in dvc_task/proc/tasks.py 9 10 11 12 13 14 15 16 17 18 19 @shared_task ( bind = True ) def run ( # pylint: disable=unused-argument self , * args : Any , ** kwargs : Any ) -> Dict [ str , Any ]: \"\"\"Run a command inside a celery task. Accepts the same arguments as `proc.process.ManagedProcess`. \"\"\" with ManagedProcess ( * args , ** kwargs ) as proc : pass return proc . info . asdict ()","title":"Tasks"},{"location":"reference/dvc_task/proc/tasks/#dvc_task.proc.tasks.run","text":"Run a command inside a celery task. Accepts the same arguments as proc.process.ManagedProcess . Source code in dvc_task/proc/tasks.py 9 10 11 12 13 14 15 16 17 18 19 @shared_task ( bind = True ) def run ( # pylint: disable=unused-argument self , * args : Any , ** kwargs : Any ) -> Dict [ str , Any ]: \"\"\"Run a command inside a celery task. Accepts the same arguments as `proc.process.ManagedProcess`. \"\"\" with ManagedProcess ( * args , ** kwargs ) as proc : pass return proc . info . asdict ()","title":"run()"},{"location":"reference/dvc_task/worker/","text":"DVC Task worker factories. TemporaryWorker Temporary worker that automatically shuts down when queue is empty. Source code in dvc_task/worker/temporary.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 class TemporaryWorker : \"\"\"Temporary worker that automatically shuts down when queue is empty.\"\"\" def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs def start ( self , name : str ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . app . control . ping ( destination = [ name ]): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,) ) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv ) @staticmethod def _parse_config ( config : Mapping [ str , Any ]) -> List [ str ]: loglevel = config . get ( \"loglevel\" , \"info\" ) argv = [ f \"--loglevel= { loglevel } \" ] for key in ( \"hostname\" , \"pool\" , \"concurrency\" , \"prefetch_multiplier\" ): value = config . get ( key ) if value : argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } = { value } \" ) for key in ( \"without_heartbeat\" , \"without_mingle\" , \"without_gossip\" , ): if config . get ( key ): argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } \" ) if config . get ( \"task_events\" ): argv . append ( \"-E\" ) return argv def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" logger . debug ( \"monitor: waiting for worker to start\" ) nodename = default_nodename ( name ) while not self . app . control . ping ( destination = [ nodename ]): # wait for worker to start time . sleep ( 1 ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () logger . info ( \"monitor: watching celery worker ' %s '\" , nodename ) while self . app . control . ping ( destination = [ nodename ]): time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ] ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) self . app . control . shutdown ( destination = [ nodename ]) break logger . info ( \"monitor: done\" ) __init__ ( app , timeout = 60 , ** kwargs ) Construct a worker. Parameters: Name Type Description Default app Celery Celery application instance. required timeout int Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. 60 Additional keyword arguments will be passed as celery worker configuration. Source code in dvc_task/worker/temporary.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs monitor ( name ) Monitor the worker and stop it when the queue is empty. Source code in dvc_task/worker/temporary.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" logger . debug ( \"monitor: waiting for worker to start\" ) nodename = default_nodename ( name ) while not self . app . control . ping ( destination = [ nodename ]): # wait for worker to start time . sleep ( 1 ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () logger . info ( \"monitor: watching celery worker ' %s '\" , nodename ) while self . app . control . ping ( destination = [ nodename ]): time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ] ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) self . app . control . shutdown ( destination = [ nodename ]) break logger . info ( \"monitor: done\" ) start ( name ) Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Parameters: Name Type Description Default name str Celery worker name. required Source code in dvc_task/worker/temporary.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def start ( self , name : str ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . app . control . ping ( destination = [ name ]): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,) ) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv )","title":"Worker"},{"location":"reference/dvc_task/worker/#dvc_task.worker.TemporaryWorker","text":"Temporary worker that automatically shuts down when queue is empty. Source code in dvc_task/worker/temporary.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 class TemporaryWorker : \"\"\"Temporary worker that automatically shuts down when queue is empty.\"\"\" def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs def start ( self , name : str ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . app . control . ping ( destination = [ name ]): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,) ) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv ) @staticmethod def _parse_config ( config : Mapping [ str , Any ]) -> List [ str ]: loglevel = config . get ( \"loglevel\" , \"info\" ) argv = [ f \"--loglevel= { loglevel } \" ] for key in ( \"hostname\" , \"pool\" , \"concurrency\" , \"prefetch_multiplier\" ): value = config . get ( key ) if value : argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } = { value } \" ) for key in ( \"without_heartbeat\" , \"without_mingle\" , \"without_gossip\" , ): if config . get ( key ): argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } \" ) if config . get ( \"task_events\" ): argv . append ( \"-E\" ) return argv def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" logger . debug ( \"monitor: waiting for worker to start\" ) nodename = default_nodename ( name ) while not self . app . control . ping ( destination = [ nodename ]): # wait for worker to start time . sleep ( 1 ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () logger . info ( \"monitor: watching celery worker ' %s '\" , nodename ) while self . app . control . ping ( destination = [ nodename ]): time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ] ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) self . app . control . shutdown ( destination = [ nodename ]) break logger . info ( \"monitor: done\" )","title":"TemporaryWorker"},{"location":"reference/dvc_task/worker/#dvc_task.worker.temporary.TemporaryWorker.__init__","text":"Construct a worker. Parameters: Name Type Description Default app Celery Celery application instance. required timeout int Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. 60 Additional keyword arguments will be passed as celery worker configuration. Source code in dvc_task/worker/temporary.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs","title":"__init__()"},{"location":"reference/dvc_task/worker/#dvc_task.worker.temporary.TemporaryWorker.monitor","text":"Monitor the worker and stop it when the queue is empty. Source code in dvc_task/worker/temporary.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" logger . debug ( \"monitor: waiting for worker to start\" ) nodename = default_nodename ( name ) while not self . app . control . ping ( destination = [ nodename ]): # wait for worker to start time . sleep ( 1 ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () logger . info ( \"monitor: watching celery worker ' %s '\" , nodename ) while self . app . control . ping ( destination = [ nodename ]): time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ] ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) self . app . control . shutdown ( destination = [ nodename ]) break logger . info ( \"monitor: done\" )","title":"monitor()"},{"location":"reference/dvc_task/worker/#dvc_task.worker.temporary.TemporaryWorker.start","text":"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Parameters: Name Type Description Default name str Celery worker name. required Source code in dvc_task/worker/temporary.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def start ( self , name : str ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . app . control . ping ( destination = [ name ]): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,) ) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv )","title":"start()"},{"location":"reference/dvc_task/worker/temporary/","text":"Temporary worker module. TemporaryWorker Temporary worker that automatically shuts down when queue is empty. Source code in dvc_task/worker/temporary.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 class TemporaryWorker : \"\"\"Temporary worker that automatically shuts down when queue is empty.\"\"\" def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs def start ( self , name : str ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . app . control . ping ( destination = [ name ]): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,) ) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv ) @staticmethod def _parse_config ( config : Mapping [ str , Any ]) -> List [ str ]: loglevel = config . get ( \"loglevel\" , \"info\" ) argv = [ f \"--loglevel= { loglevel } \" ] for key in ( \"hostname\" , \"pool\" , \"concurrency\" , \"prefetch_multiplier\" ): value = config . get ( key ) if value : argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } = { value } \" ) for key in ( \"without_heartbeat\" , \"without_mingle\" , \"without_gossip\" , ): if config . get ( key ): argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } \" ) if config . get ( \"task_events\" ): argv . append ( \"-E\" ) return argv def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" logger . debug ( \"monitor: waiting for worker to start\" ) nodename = default_nodename ( name ) while not self . app . control . ping ( destination = [ nodename ]): # wait for worker to start time . sleep ( 1 ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () logger . info ( \"monitor: watching celery worker ' %s '\" , nodename ) while self . app . control . ping ( destination = [ nodename ]): time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ] ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) self . app . control . shutdown ( destination = [ nodename ]) break logger . info ( \"monitor: done\" ) __init__ ( app , timeout = 60 , ** kwargs ) Construct a worker. Parameters: Name Type Description Default app Celery Celery application instance. required timeout int Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. 60 Additional keyword arguments will be passed as celery worker configuration. Source code in dvc_task/worker/temporary.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs monitor ( name ) Monitor the worker and stop it when the queue is empty. Source code in dvc_task/worker/temporary.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" logger . debug ( \"monitor: waiting for worker to start\" ) nodename = default_nodename ( name ) while not self . app . control . ping ( destination = [ nodename ]): # wait for worker to start time . sleep ( 1 ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () logger . info ( \"monitor: watching celery worker ' %s '\" , nodename ) while self . app . control . ping ( destination = [ nodename ]): time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ] ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) self . app . control . shutdown ( destination = [ nodename ]) break logger . info ( \"monitor: done\" ) start ( name ) Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Parameters: Name Type Description Default name str Celery worker name. required Source code in dvc_task/worker/temporary.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def start ( self , name : str ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . app . control . ping ( destination = [ name ]): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,) ) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv )","title":"Temporary"},{"location":"reference/dvc_task/worker/temporary/#dvc_task.worker.temporary.TemporaryWorker","text":"Temporary worker that automatically shuts down when queue is empty. Source code in dvc_task/worker/temporary.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 class TemporaryWorker : \"\"\"Temporary worker that automatically shuts down when queue is empty.\"\"\" def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs def start ( self , name : str ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . app . control . ping ( destination = [ name ]): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,) ) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv ) @staticmethod def _parse_config ( config : Mapping [ str , Any ]) -> List [ str ]: loglevel = config . get ( \"loglevel\" , \"info\" ) argv = [ f \"--loglevel= { loglevel } \" ] for key in ( \"hostname\" , \"pool\" , \"concurrency\" , \"prefetch_multiplier\" ): value = config . get ( key ) if value : argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } = { value } \" ) for key in ( \"without_heartbeat\" , \"without_mingle\" , \"without_gossip\" , ): if config . get ( key ): argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } \" ) if config . get ( \"task_events\" ): argv . append ( \"-E\" ) return argv def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" logger . debug ( \"monitor: waiting for worker to start\" ) nodename = default_nodename ( name ) while not self . app . control . ping ( destination = [ nodename ]): # wait for worker to start time . sleep ( 1 ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () logger . info ( \"monitor: watching celery worker ' %s '\" , nodename ) while self . app . control . ping ( destination = [ nodename ]): time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ] ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) self . app . control . shutdown ( destination = [ nodename ]) break logger . info ( \"monitor: done\" )","title":"TemporaryWorker"},{"location":"reference/dvc_task/worker/temporary/#dvc_task.worker.temporary.TemporaryWorker.__init__","text":"Construct a worker. Parameters: Name Type Description Default app Celery Celery application instance. required timeout int Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. 60 Additional keyword arguments will be passed as celery worker configuration. Source code in dvc_task/worker/temporary.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs","title":"__init__()"},{"location":"reference/dvc_task/worker/temporary/#dvc_task.worker.temporary.TemporaryWorker.monitor","text":"Monitor the worker and stop it when the queue is empty. Source code in dvc_task/worker/temporary.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" logger . debug ( \"monitor: waiting for worker to start\" ) nodename = default_nodename ( name ) while not self . app . control . ping ( destination = [ nodename ]): # wait for worker to start time . sleep ( 1 ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () logger . info ( \"monitor: watching celery worker ' %s '\" , nodename ) while self . app . control . ping ( destination = [ nodename ]): time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ] ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) self . app . control . shutdown ( destination = [ nodename ]) break logger . info ( \"monitor: done\" )","title":"monitor()"},{"location":"reference/dvc_task/worker/temporary/#dvc_task.worker.temporary.TemporaryWorker.start","text":"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Parameters: Name Type Description Default name str Celery worker name. required Source code in dvc_task/worker/temporary.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def start ( self , name : str ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . app . control . ping ( destination = [ name ]): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,) ) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv )","title":"start()"}]}